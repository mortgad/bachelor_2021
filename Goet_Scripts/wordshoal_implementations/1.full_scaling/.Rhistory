library(methods)
#create incrementer
inc <- function(x)
{
eval.parent(substitute(x <- x + 1))
}
#load dataset
system.time(dataset <- fread("../../raw_data/ukhcdeb_ppr.csv",header=T,stringsAsFactors = FALSE))
custom_list <- c("a","an","and","are","as","at","be","by","for","from",
"has","he","in","is","it","its","of","on","that","the",
"to","was","were","will","with")
#divide dataset by session
data_per_session <- split(dataset,dataset$session_ref)
rm(list=c("dataset"))
#loop over
for(s in 1:length(data_per_session)){
#store data for this loop
session_data <- data_per_session[[s]]
session_data$speech_content <- gsub('\"','',session_data$speech_content)
session_data <- session_data[nchar(session_data$matched_name)>0,]
session_data <- session_data[nchar(session_data$matched_name)<25,]
session_data$matched_name <- word(session_data$matched_name,-1)
#aggregate all speeches by member and party
session_data <- aggregate(session_data$speech_content,by=list(session_data$matched_name,session_data$role,session_data$party,session_data$session_ref,session_data$session_indicator),paste,collapse=",")
colnames(session_data) <- c("speaker","role","party","session_ref","session_indicator","speech")
#############################
#apply wordfish
#############################
text <- session_data$speech
labels <- data.frame(party=session_data$party,speaker=session_data$speaker,session_ref=session_data$session_ref,session_indicator=session_data$session_indicator)
if(length(unique(labels$party))>=2){
text.corpus   <- Corpus(VectorSource(text))
text.corpus <- tm_map(text.corpus, removeWords, custom_list)
# documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T,weighting = function(x) weightTfIdf(x, normalize = FALSE)))
documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T))
docs_f      <- removeSparseTerms(documents, 0.80)
wcdata      <- wfm(as.matrix(docs_f))
rowTotals   <- apply(wcdata , 1, sum) #Find the sum of words in each Document
wcdata      <- wcdata[rowTotals> 0, ]
wcdata <- wcdata[,colSums(wcdata)>0]
rownumbers <- 1:nrow(labels)
labels <- data.frame(number=rownumbers,party=labels$party,speaker=labels$speaker,session_indicator=labels$session_indicator,session_ref=labels$session_ref)
colnames(labels) <- c("number","party","speaker","session_indicator","session_ref")
dir1 <- 1
dir2 <- dim(wcdata)[2]
if(dim(wcdata)[2]>=5){
results     <- wordfish(wfm=wcdata,dir=c(dir1,dir2))
theta_file    <- data.frame(id = results$docs, theta=results$theta,se.theta=results$se.theta,party=labels$party[rownames(labels) %in% results$docs],speaker=labels$speaker[rownames(labels) %in% results$docs])
theta_file$session_ref <- rep(unique(labels$session_ref),nrow(theta_file))
theta_file$session_indicator <- rep(unique(labels$session_indicator),nrow(theta_file))
theta_file$theta <- scale(theta_file$theta,center=T,scale=T) # rescale with mean = center, variance = 1
#############################
#apply CA
#############################
ca_results  <- ca(wcdata)
ca_file  <- data.frame(score=ca_results$colcoord[,1])
ca_file$score <- scale(ca_file$score,center=T,scale=T) # rescale with mean = center, variance = 1
s <- dim(t(wcdata))[2]
#check whether the first dimension accounts for more than what we would expect at random
random_accounts <- 100/(s-1)
singular_values <- ca_results$sv
inertia <- singular_values^2
pct <- 100*inertia/sum(inertia)
actual_account <- ca_results
x <- 0
for (p in pct){
if (p > random_accounts){
inc(x)
}}
dimensions <- x
perc.dim1 <- pct[1]
ca_file$dimensions <- rep(dimensions,nrow(ca_file))
ca_file$perc.dim1 <- rep(perc.dim1,nrow(ca_file))
#############################
#Combine CA and Wordfish results in one file
#############################
combined_results <- data.frame(id=theta_file$id,theta=theta_file$theta,se.theta=theta_file$se.theta,party=theta_file$party,speaker=theta_file$speaker,session_ref=theta_file$session_ref,session_indicator=theta_file$session_indicator,score=ca_file$score,dimensions=ca_file$dimensions,perc.dim1=ca_file$perc.dim1)
#appends results to csv
setwd(dataPath)
if(s == 1){
write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = T, append = T,row.names=F)}
else{write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = F, append = T,row.names=F)}
print(paste("Writing our results for session ",combined_results$session_ref[1],sep=""))
}
rm(list=c("text.corpus","documents","docs_f","wcdata","theta_file","ca_file"))
}
}#end loop over data_per session
#looking
combined_results <- read.csv("../full_scaling_estimates_ps.csv",header=T,stringsAsFactors=F)
combined_results <- combined_results[combined_results$session_ref!="session_ref",]
combined_results_per_session <- combined_results[order(combined_results$session_indicator),]
combined_results_per_session <- split(combined_results_per_session,combined_results_per_session$session_ref)
correlations <- list()
for(i in 1:length(combined_results_per_session)){
data <- combined_results_per_session[[i]]
if(nrow(data)>0){
correlations[[i]] <- data.frame(cor = cor.test(as.numeric(as.character(data$theta)),as.numeric(as.character(data$score)))$estimate)
}
}
final_correlations <- do.call(rbind.data.frame,correlations)
final_correlations <- abs(final_correlations$cor)
mean(final_correlations)
#asses dimensionality and perc. explained by first dimension
dimension_data <- unique(data.frame(dimensions = combined_results$dimensions,perc.dim1 = combined_results$perc.dim1, session_ref = combined_results$session_ref))
mean(as.numeric(as.character(dimension_data$dimensions)))
mean(as.numeric(as.character(dimension_data$perc.dim1)))
dataPath <- gsub("full_scaling.R","",rstudioapi::getSourceEditorContext()$path)
library(base)
library(ca)
library(Hmisc)
library(data.table)
library(stringr)
library(tm)
library(austin)
library(methods)
inc <- function(x)
{
eval.parent(substitute(x <- x + 1))
}
system.time(dataset <- fread("../../raw_data/ukhcdeb_ppr.csv",header=T,stringsAsFactors = FALSE))
getwd()
system.time(dataset <- fread("../raw_data/ukhcdeb_ppr.csv",header=T,stringsAsFactors = FALSE))
custom_list <- c("a","an","and","are","as","at","be","by","for","from",
"has","he","in","is","it","its","of","on","that","the",
"to","was","were","will","with")
#divide dataset by session
data_per_session <- split(dataset,dataset$session_ref)
rm(list=c("dataset"))
#loop over
for(s in 1:length(data_per_session)){
#store data for this loop
session_data <- data_per_session[[s]]
session_data$speech_content <- gsub('\"','',session_data$speech_content)
session_data <- session_data[nchar(session_data$matched_name)>0,]
session_data <- session_data[nchar(session_data$matched_name)<25,]
session_data$matched_name <- word(session_data$matched_name,-1)
#aggregate all speeches by member and party
session_data <- aggregate(session_data$speech_content,by=list(session_data$matched_name,session_data$role,session_data$party,session_data$session_ref,session_data$session_indicator),paste,collapse=",")
colnames(session_data) <- c("speaker","role","party","session_ref","session_indicator","speech")
#############################
#apply wordfish
#############################
text <- session_data$speech
labels <- data.frame(party=session_data$party,speaker=session_data$speaker,session_ref=session_data$session_ref,session_indicator=session_data$session_indicator)
if(length(unique(labels$party))>=2){
text.corpus   <- Corpus(VectorSource(text))
text.corpus <- tm_map(text.corpus, removeWords, custom_list)
# documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T,weighting = function(x) weightTfIdf(x, normalize = FALSE)))
documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T))
docs_f      <- removeSparseTerms(documents, 0.80)
wcdata      <- wfm(as.matrix(docs_f))
rowTotals   <- apply(wcdata , 1, sum) #Find the sum of words in each Document
wcdata      <- wcdata[rowTotals> 0, ]
wcdata <- wcdata[,colSums(wcdata)>0]
rownumbers <- 1:nrow(labels)
labels <- data.frame(number=rownumbers,party=labels$party,speaker=labels$speaker,session_indicator=labels$session_indicator,session_ref=labels$session_ref)
colnames(labels) <- c("number","party","speaker","session_indicator","session_ref")
dir1 <- 1
dir2 <- dim(wcdata)[2]
if(dim(wcdata)[2]>=5){
results     <- wordfish(wfm=wcdata,dir=c(dir1,dir2))
theta_file    <- data.frame(id = results$docs, theta=results$theta,se.theta=results$se.theta,party=labels$party[rownames(labels) %in% results$docs],speaker=labels$speaker[rownames(labels) %in% results$docs])
theta_file$session_ref <- rep(unique(labels$session_ref),nrow(theta_file))
theta_file$session_indicator <- rep(unique(labels$session_indicator),nrow(theta_file))
theta_file$theta <- scale(theta_file$theta,center=T,scale=T) # rescale with mean = center, variance = 1
#############################
#apply CA
#############################
ca_results  <- ca(wcdata)
ca_file  <- data.frame(score=ca_results$colcoord[,1])
ca_file$score <- scale(ca_file$score,center=T,scale=T) # rescale with mean = center, variance = 1
s <- dim(t(wcdata))[2]
#check whether the first dimension accounts for more than what we would expect at random
random_accounts <- 100/(s-1)
singular_values <- ca_results$sv
inertia <- singular_values^2
pct <- 100*inertia/sum(inertia)
actual_account <- ca_results
x <- 0
for (p in pct){
if (p > random_accounts){
inc(x)
}}
dimensions <- x
perc.dim1 <- pct[1]
ca_file$dimensions <- rep(dimensions,nrow(ca_file))
ca_file$perc.dim1 <- rep(perc.dim1,nrow(ca_file))
#############################
#Combine CA and Wordfish results in one file
#############################
combined_results <- data.frame(id=theta_file$id,theta=theta_file$theta,se.theta=theta_file$se.theta,party=theta_file$party,speaker=theta_file$speaker,session_ref=theta_file$session_ref,session_indicator=theta_file$session_indicator,score=ca_file$score,dimensions=ca_file$dimensions,perc.dim1=ca_file$perc.dim1)
#appends results to csv
setwd(dataPath)
if(s == 1){
write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = T, append = T,row.names=F)}
else{write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = F, append = T,row.names=F)}
print(paste("Writing our results for session ",combined_results$session_ref[1],sep=""))
}
rm(list=c("text.corpus","documents","docs_f","wcdata","theta_file","ca_file"))
}
}#end loop over data_per session
set.seed(12345)
dataPath <- gsub("full_scaling.R","",rstudioapi::getSourceEditorContext()$path)
library(base)
library(ca)
library(Hmisc)
library(data.table)
library(stringr)
library(tm)
library(austin)
library(methods)
#create incrementer
inc <- function(x)
{
eval.parent(substitute(x <- x + 1))
}
#load dataset
system.time(dataset <- fread("../raw_data/ukhcdeb_ppr.csv",header=T,stringsAsFactors = FALSE))
custom_list <- c("a","an","and","are","as","at","be","by","for","from",
"has","he","in","is","it","its","of","on","that","the",
"to","was","were","will","with")
#divide dataset by session
data_per_session <- split(dataset,dataset$session_ref)
rm(list=c("dataset"))
#loop over
for(s in 1:length(data_per_session)){
#store data for this loop
session_data <- data_per_session[[s]]
session_data$speech_content <- gsub('\"','',session_data$speech_content)
session_data <- session_data[nchar(session_data$matched_name)>0,]
session_data <- session_data[nchar(session_data$matched_name)<25,]
session_data$matched_name <- word(session_data$matched_name,-1)
#aggregate all speeches by member and party
session_data <- aggregate(session_data$speech_content,by=list(session_data$matched_name,session_data$role,session_data$party,session_data$session_ref,session_data$session_indicator),paste,collapse=",")
colnames(session_data) <- c("speaker","role","party","session_ref","session_indicator","speech")
#############################
#apply wordfish
#############################
text <- session_data$speech
labels <- data.frame(party=session_data$party,speaker=session_data$speaker,session_ref=session_data$session_ref,session_indicator=session_data$session_indicator)
if(length(unique(labels$party))>=2){
text.corpus   <- Corpus(VectorSource(text))
text.corpus <- tm_map(text.corpus, removeWords, custom_list)
# documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T,weighting = function(x) weightTfIdf(x, normalize = FALSE)))
documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T))
docs_f      <- removeSparseTerms(documents, 0.80)
wcdata      <- wfm(as.matrix(docs_f))
rowTotals   <- apply(wcdata , 1, sum) #Find the sum of words in each Document
wcdata      <- wcdata[rowTotals> 0, ]
wcdata <- wcdata[,colSums(wcdata)>0]
rownumbers <- 1:nrow(labels)
labels <- data.frame(number=rownumbers,party=labels$party,speaker=labels$speaker,session_indicator=labels$session_indicator,session_ref=labels$session_ref)
colnames(labels) <- c("number","party","speaker","session_indicator","session_ref")
dir1 <- 1
dir2 <- dim(wcdata)[2]
if(dim(wcdata)[2]>=5){
results     <- wordfish(wfm=wcdata,dir=c(dir1,dir2))
theta_file    <- data.frame(id = results$docs, theta=results$theta,se.theta=results$se.theta,party=labels$party[rownames(labels) %in% results$docs],speaker=labels$speaker[rownames(labels) %in% results$docs])
theta_file$session_ref <- rep(unique(labels$session_ref),nrow(theta_file))
theta_file$session_indicator <- rep(unique(labels$session_indicator),nrow(theta_file))
theta_file$theta <- scale(theta_file$theta,center=T,scale=T) # rescale with mean = center, variance = 1
#############################
#apply CA
#############################
ca_results  <- ca(wcdata)
ca_file  <- data.frame(score=ca_results$colcoord[,1])
ca_file$score <- scale(ca_file$score,center=T,scale=T) # rescale with mean = center, variance = 1
s <- dim(t(wcdata))[2]
#check whether the first dimension accounts for more than what we would expect at random
random_accounts <- 100/(s-1)
singular_values <- ca_results$sv
inertia <- singular_values^2
pct <- 100*inertia/sum(inertia)
actual_account <- ca_results
x <- 0
for (p in pct){
if (p > random_accounts){
inc(x)
}}
dimensions <- x
perc.dim1 <- pct[1]
ca_file$dimensions <- rep(dimensions,nrow(ca_file))
ca_file$perc.dim1 <- rep(perc.dim1,nrow(ca_file))
#############################
#Combine CA and Wordfish results in one file
#############################
combined_results <- data.frame(id=theta_file$id,theta=theta_file$theta,se.theta=theta_file$se.theta,party=theta_file$party,speaker=theta_file$speaker,session_ref=theta_file$session_ref,session_indicator=theta_file$session_indicator,score=ca_file$score,dimensions=ca_file$dimensions,perc.dim1=ca_file$perc.dim1)
#appends results to csv
setwd(dataPath)
if(s == 1){
write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = T, append = T,row.names=T)}
else{write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = F, append = T,row.names=F)}
print(paste("Writing our results for session ",combined_results$session_ref[1],sep=""))
}
rm(list=c("text.corpus","documents","docs_f","wcdata","theta_file","ca_file"))
}
}#end loop over data_per session
set.seed(12345)
dataPath <- gsub("full_scaling.R","",rstudioapi::getSourceEditorContext()$path)
library(base)
library(ca)
library(Hmisc)
library(data.table)
library(stringr)
library(tm)
library(austin)
library(methods)
#create incrementer
inc <- function(x)
{
eval.parent(substitute(x <- x + 1))
}
#load dataset
system.time(dataset <- fread("../raw_data/ukhcdeb_ppr.csv",header=T,stringsAsFactors = FALSE))
custom_list <- c("a","an","and","are","as","at","be","by","for","from",
"has","he","in","is","it","its","of","on","that","the",
"to","was","were","will","with")
#divide dataset by session
data_per_session <- split(dataset,dataset$session_ref)
rm(list=c("dataset"))
#loop over
loop <- 1
for(s in 1:length(data_per_session)){
#store data for this loop
session_data <- data_per_session[[s]]
session_data$speech_content <- gsub('\"','',session_data$speech_content)
session_data <- session_data[nchar(session_data$matched_name)>0,]
session_data <- session_data[nchar(session_data$matched_name)<25,]
session_data$matched_name <- word(session_data$matched_name,-1)
#aggregate all speeches by member and party
session_data <- aggregate(session_data$speech_content,by=list(session_data$matched_name,session_data$role,session_data$party,session_data$session_ref,session_data$session_indicator),paste,collapse=",")
colnames(session_data) <- c("speaker","role","party","session_ref","session_indicator","speech")
#############################
#apply wordfish
#############################
text <- session_data$speech
labels <- data.frame(party=session_data$party,speaker=session_data$speaker,session_ref=session_data$session_ref,session_indicator=session_data$session_indicator)
if(length(unique(labels$party))>=2){
text.corpus   <- Corpus(VectorSource(text))
text.corpus <- tm_map(text.corpus, removeWords, custom_list)
# documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T,weighting = function(x) weightTfIdf(x, normalize = FALSE)))
documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T))
docs_f      <- removeSparseTerms(documents, 0.80)
wcdata      <- wfm(as.matrix(docs_f))
rowTotals   <- apply(wcdata , 1, sum) #Find the sum of words in each Document
wcdata      <- wcdata[rowTotals> 0, ]
wcdata <- wcdata[,colSums(wcdata)>0]
rownumbers <- 1:nrow(labels)
labels <- data.frame(number=rownumbers,party=labels$party,speaker=labels$speaker,session_indicator=labels$session_indicator,session_ref=labels$session_ref)
colnames(labels) <- c("number","party","speaker","session_indicator","session_ref")
dir1 <- 1
dir2 <- dim(wcdata)[2]
if(dim(wcdata)[2]>=5){
results     <- wordfish(wfm=wcdata,dir=c(dir1,dir2))
theta_file    <- data.frame(id = results$docs, theta=results$theta,se.theta=results$se.theta,party=labels$party[rownames(labels) %in% results$docs],speaker=labels$speaker[rownames(labels) %in% results$docs])
theta_file$session_ref <- rep(unique(labels$session_ref),nrow(theta_file))
theta_file$session_indicator <- rep(unique(labels$session_indicator),nrow(theta_file))
theta_file$theta <- scale(theta_file$theta,center=T,scale=T) # rescale with mean = center, variance = 1
#############################
#apply CA
#############################
ca_results  <- ca(wcdata)
ca_file  <- data.frame(score=ca_results$colcoord[,1])
ca_file$score <- scale(ca_file$score,center=T,scale=T) # rescale with mean = center, variance = 1
s <- dim(t(wcdata))[2]
#check whether the first dimension accounts for more than what we would expect at random
random_accounts <- 100/(s-1)
singular_values <- ca_results$sv
inertia <- singular_values^2
pct <- 100*inertia/sum(inertia)
actual_account <- ca_results
x <- 0
for (p in pct){
if (p > random_accounts){
inc(x)
}}
dimensions <- x
perc.dim1 <- pct[1]
ca_file$dimensions <- rep(dimensions,nrow(ca_file))
ca_file$perc.dim1 <- rep(perc.dim1,nrow(ca_file))
#############################
#Combine CA and Wordfish results in one file
#############################
combined_results <- data.frame(id=theta_file$id,theta=theta_file$theta,se.theta=theta_file$se.theta,party=theta_file$party,speaker=theta_file$speaker,session_ref=theta_file$session_ref,session_indicator=theta_file$session_indicator,score=ca_file$score,dimensions=ca_file$dimensions,perc.dim1=ca_file$perc.dim1)
#appends results to csv
setwd(dataPath)
if(loop == 1){
write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = T, append = T,row.names=T)}
else{write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = F, append = T,row.names=F)}
print(paste("Writing our results for session ",combined_results$session_ref[1],sep=""))
loop <- loop + 1
}
rm(list=c("text.corpus","documents","docs_f","wcdata","theta_file","ca_file"))
}
}#end loop over data_per session
set.seed(12345)
dataPath <- gsub("full_scaling.R","",rstudioapi::getSourceEditorContext()$path)
library(base)
library(ca)
library(Hmisc)
library(data.table)
library(stringr)
library(tm)
library(austin)
library(methods)
#create incrementer
inc <- function(x)
{
eval.parent(substitute(x <- x + 1))
}
#load dataset
system.time(dataset <- fread("../../raw_data/ukhcdeb_ppr.csv",header=T,stringsAsFactors = FALSE))
custom_list <- c("a","an","and","are","as","at","be","by","for","from",
"has","he","in","is","it","its","of","on","that","the",
"to","was","were","will","with")
#divide dataset by session
data_per_session <- split(dataset,dataset$session_ref)
rm(list=c("dataset"))
#loop over
loop <- 1
for(s in 1:length(data_per_session)){
#store data for this loop
session_data <- data_per_session[[s]]
session_data$speech_content <- gsub('\"','',session_data$speech_content)
session_data <- session_data[nchar(session_data$matched_name)>0,]
session_data <- session_data[nchar(session_data$matched_name)<25,]
session_data$matched_name <- word(session_data$matched_name,-1)
#aggregate all speeches by member and party
session_data <- aggregate(session_data$speech_content,by=list(session_data$matched_name,session_data$role,session_data$party,session_data$session_ref,session_data$session_indicator),paste,collapse=",")
colnames(session_data) <- c("speaker","role","party","session_ref","session_indicator","speech")
#############################
#apply wordfish
#############################
text <- session_data$speech
labels <- data.frame(party=session_data$party,speaker=session_data$speaker,session_ref=session_data$session_ref,session_indicator=session_data$session_indicator)
if(length(unique(labels$party))>=2){
text.corpus   <- Corpus(VectorSource(text))
text.corpus <- tm_map(text.corpus, removeWords, custom_list)
# documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T,weighting = function(x) weightTfIdf(x, normalize = FALSE)))
documents   <- TermDocumentMatrix(text.corpus, control = list(removePunctuation=T,tolower=T,removeNumbers=T))
docs_f      <- removeSparseTerms(documents, 0.80)
wcdata      <- wfm(as.matrix(docs_f))
rowTotals   <- apply(wcdata , 1, sum) #Find the sum of words in each Document
wcdata      <- wcdata[rowTotals> 0, ]
wcdata <- wcdata[,colSums(wcdata)>0]
rownumbers <- 1:nrow(labels)
labels <- data.frame(number=rownumbers,party=labels$party,speaker=labels$speaker,session_indicator=labels$session_indicator,session_ref=labels$session_ref)
colnames(labels) <- c("number","party","speaker","session_indicator","session_ref")
dir1 <- 1
dir2 <- dim(wcdata)[2]
if(dim(wcdata)[2]>=5){
results     <- wordfish(wfm=wcdata,dir=c(dir1,dir2))
theta_file    <- data.frame(id = results$docs, theta=results$theta,se.theta=results$se.theta,party=labels$party[rownames(labels) %in% results$docs],speaker=labels$speaker[rownames(labels) %in% results$docs])
theta_file$session_ref <- rep(unique(labels$session_ref),nrow(theta_file))
theta_file$session_indicator <- rep(unique(labels$session_indicator),nrow(theta_file))
theta_file$theta <- scale(theta_file$theta,center=T,scale=T) # rescale with mean = center, variance = 1
#############################
#apply CA
#############################
ca_results  <- ca(wcdata)
ca_file  <- data.frame(score=ca_results$colcoord[,1])
ca_file$score <- scale(ca_file$score,center=T,scale=T) # rescale with mean = center, variance = 1
s <- dim(t(wcdata))[2]
#check whether the first dimension accounts for more than what we would expect at random
random_accounts <- 100/(s-1)
singular_values <- ca_results$sv
inertia <- singular_values^2
pct <- 100*inertia/sum(inertia)
actual_account <- ca_results
x <- 0
for (p in pct){
if (p > random_accounts){
inc(x)
}}
dimensions <- x
perc.dim1 <- pct[1]
ca_file$dimensions <- rep(dimensions,nrow(ca_file))
ca_file$perc.dim1 <- rep(perc.dim1,nrow(ca_file))
#############################
#Combine CA and Wordfish results in one file
#############################
combined_results <- data.frame(id=theta_file$id,theta=theta_file$theta,se.theta=theta_file$se.theta,party=theta_file$party,speaker=theta_file$speaker,session_ref=theta_file$session_ref,session_indicator=theta_file$session_indicator,score=ca_file$score,dimensions=ca_file$dimensions,perc.dim1=ca_file$perc.dim1)
#appends results to csv
setwd(dataPath)
if(loop == 1){
write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = T, append = T,row.names=F)}
else{write.table(combined_results, "../full_scaling_estimates_ps.csv", sep = ",", col.names = F, append = T,row.names=F)}
print(paste("Writing our results for session ",combined_results$session_ref[1],sep=""))
loop <- loop + 1
}
rm(list=c("text.corpus","documents","docs_f","wcdata","theta_file","ca_file"))
}
}#end loop over data_per session
#looking
combined_results <- read.csv("../full_scaling_estimates_ps.csv",header=T,stringsAsFactors=F)
combined_results <- combined_results[combined_results$session_ref!="session_ref",]
combined_results_per_session <- combined_results[order(combined_results$session_indicator),]
combined_results_per_session <- split(combined_results_per_session,combined_results_per_session$session_ref)
correlations <- list()
for(i in 1:length(combined_results_per_session)){
data <- combined_results_per_session[[i]]
if(nrow(data)>0){
correlations[[i]] <- data.frame(cor = cor.test(as.numeric(as.character(data$theta)),as.numeric(as.character(data$score)))$estimate)
}
}
final_correlations <- do.call(rbind.data.frame,correlations)
final_correlations <- abs(final_correlations$cor)
mean(final_correlations)
#asses dimensionality and perc. explained by first dimension
dimension_data <- unique(data.frame(dimensions = combined_results$dimensions,perc.dim1 = combined_results$perc.dim1, session_ref = combined_results$session_ref))
mean(as.numeric(as.character(dimension_data$dimensions)))
mean(as.numeric(as.character(dimension_data$perc.dim1)))
