library(reshape)
#install.packages("reshape2")
library(reshape2)
#install.packages("Hmisc")
library(Hmisc)
#create incrementer
inc <- function(x)
{
eval.parent(substitute(x <- x + 1))
}
dataPath <- gsub("wordshoal_with_ca_ps.R","",rstudioapi::getSourceEditorContext()$path)
setwd(paste(dataPath,"wfms_ps2",sep=""))
set.seed(42)
fullrun <- TRUE
mcmc.adapt <- 500
mcmc.burn <- 500
mcmc.sample <- 2000
mcmc.thin <- 2
library(rjags)
source("Wordshoal9.R")
##########################################
## Load UK Speech Data  ##
##########################################
#counts
speech_number <- 0
debate_number <- 0
legislator_number <- 0
#create empty_list
all_results <- list()
wordseine_list <- list()
#read in files
library(base)
fileNames <- Sys.glob("*.RData")
for (fileName in 1:length(fileNames)) { #start loop
print(fileNames[fileName])
data.path <- fileNames[fileName]
load(data.path)
################################
## Run Wordfish on all debates, per session ##
################################
#create new index
debateData$debateID <- 1:nrow(debateData)
debateSpeakerData$debateID <- rep(debateData$debateID,data.frame(table(debateSpeakerData$debateID))$Freq)
debateSpeakerData <- debateSpeakerData[order(debateSpeakerData$party),]
debateSpeakerData$Freq <- rep(data.frame(table(debateSpeakerData$party))$Freq,data.frame(table(debateSpeakerData$party))$Freq)
debateSpeakerData <- debateSpeakerData[order(debateSpeakerData$party),]
debateSpeakerData$Freq <- rep(data.frame(table(debateSpeakerData$party))$Freq,data.frame(table(debateSpeakerData$party))$Freq)
#get rid of unmatched
debateSpeakerData <-  debateSpeakerData[which(!(debateSpeakerData$party %in% c("unknown","none"))),]
debateSpeakerData <- debateSpeakerData[order(debateSpeakerData$debateID),]
if(dim(debateSpeakerData)[1] > 0){
rownames(debateSpeakerData) <- 1:nrow(debateSpeakerData)
rownames(speakerData) <- 1:nrow(speakerData)
#ensure debateData is limited to remaining debates
debateData <- debateData[which(debateData$debateID %in% debateSpeakerData$debateID),]
rownames(debateData) <- 1:nrow(debateData)
speakerData <- speakerData[which(speakerData$speakerID %in% debateSpeakerData$speakerID),]
rownames(speakerData) <- 1:nrow(speakerData)
####################
#take out speakers
####################
speakerWFM.byDebate <- speakerWFM.byDebate[debateData$debateID]
#first order the debateSpeakerData
debateSpeakerData <- debateSpeakerData[order(debateSpeakerData$debateID),]
debateData <- debateData[order(debateData$debateID),]
#now create list
debateSpeakerDataList <- split(debateSpeakerData, debateSpeakerData$debateID)
speakerWFM.byDebate.temp <- list()
#check the number of individual contributions per party label in each debate
for(i in 1:length(debateSpeakerDataList)){
temp <- debateSpeakerDataList[[i]]
temp_wfm <- speakerWFM.byDebate[[i]]
temp$Freq2 <- rep(data.frame(table(temp$party))$Freq,data.frame(table(temp$party))$Freq)
######################################
#set number of times a party members should speak to be included
#####################################
temp$share <- temp$Freq2/nrow(temp)
temp <- temp[temp$share > .19,] #more than once in debate
temp_wfm2 <- temp_wfm[as.numeric(rownames(temp_wfm)) %in% temp$speakerID,]
#guard against SVD error
rowTotals   <- apply(temp_wfm2 , 1, sum) #Find the sum of words in each Document
temp_wfm2   		<- temp_wfm2[rowTotals> 0, ]
if(!is.null(dim(temp_wfm2))){
#deal with duplicates
temp_wfm2 <- temp_wfm2[!duplicated(rownames(temp_wfm2)),]
if(!is.null(dim(temp_wfm2))){
#deal with non-zero entries of words
temp_wfm2 <- temp_wfm2[,colSums(temp_wfm2)>0]
if(length(unique(temp$party))>1 & nrow(temp) > 4){
debateSpeakerDataList[[i]] <- temp
speakerWFM.byDebate.temp[[i]] <- temp_wfm2
}
}
}
}
if(length(speakerWFM.byDebate.temp)>0){
#get rid of NULL values
speakerWFM.byDebate <- speakerWFM.byDebate.temp[!(sapply(speakerWFM.byDebate.temp,is.null))]
debateSpeakerDataList <- debateSpeakerDataList[!(sapply(speakerWFM.byDebate.temp,is.null))]
debateSpeakerDataList  <- debateSpeakerDataList[1:length(speakerWFM.byDebate)]
#########################
#now check the debateSpeakerList
debateSpeakerDataList2 <- list()
for(i in 1:length(speakerWFM.byDebate)){
checkNames <- rownames(speakerWFM.byDebate[[i]])
temp <- debateSpeakerDataList[[i]][debateSpeakerDataList[[i]]$speakerID %in% as.numeric(checkNames),]
temp <- temp[!duplicated(temp$speakerID),]
debateSpeakerDataList2[[i]] <- temp
}
#############
#now create debateSpeakerData dataframe
############
library(plyr)
debateSpeakerData <- ldply(debateSpeakerDataList2, data.frame)
#reset datasets
debateData <- debateData[which(debateData$debateID %in% debateSpeakerData$debateID),]
speakerData <- speakerData[which(speakerData$speakerID %in% debateSpeakerData$speakerID),]
rownames(speakerData) <- 1:nrow(speakerData)
#repair number of speakers
debateData$speakersN <- data.frame(table(debateSpeakerData$debateID))$Freq
debateSpeakerData$speakersN <- rep(data.frame(table(debateSpeakerData$debateID))$Freq,data.frame(table(debateSpeakerData$debateID))$Freq)
debateData <- debateData[which(debateData$debateID %in% debateSpeakerData$debateID),]
#rownames(debateData) <- 1:nrow(debateData)
speakerData <- speakerData[which(speakerData$speakerID %in% debateSpeakerData$speakerID),]
rownames(speakerData) <- 1:nrow(speakerData)
###############
if (fullrun){
#create necessary docs
wordseine.tmp <- wordseine(speakerWFM.byDebate)
wordfish.details <- wordseine.tmp$wordfish.details
wordseine.out <- wordseine.tmp$debate.scaling.results
save(wordseine.out,file="Estimates/WordSeineUK.Rdata")
save(wordfish.details,file="Estimates/WordfishUK.Rdata")
#############################
#apply CA
#############################
ca_files <- list()
for(wfm in 1:length(speakerWFM.byDebate)){
wcdata <- speakerWFM.byDebate[[wfm]]
ca_results  <- ca(t(wcdata))
ca_file  <- data.frame(score=ca_results$colcoord[,1])
#ca_file$score <- scale(ca_file$score,center=T,scale=T) # rescale with mean = center, variance = 1
s <- dim(t(wcdata))[2]
#check whether the first dimension accounts for more than what we would expect at random
random_accounts <- 100/(s-1)
singular_values <- ca_results$sv
inertia <- singular_values^2
pct <- 100*inertia/sum(inertia)
actual_account <- ca_results
x <- 0
for (p in pct){
if (p > random_accounts){
inc(x)
}}
dimensions <- x
perc.dim1 <- pct[1]
ca_file$dimensions <- rep(dimensions,nrow(ca_file))
ca_file$perc.dim1 <- rep(perc.dim1,nrow(ca_file))
ca_files[[wfm]] <- ca_file
}
#############################
#Combine CA and Wordfish results in one file
#############################
} else {
load("Estimates/WordSeineUK.Rdata")
load("Estimates/WordfishUK.Rdata")
}
ca_file_final <- do.call(rbind.data.frame,ca_files)
print(names(wordseine.out))
new_file <- data.frame(debateID = wordseine.out$Debate, Legislator = wordseine.out$Legislator,speaker.name = debateSpeakerData$speaker.name, Score=wordseine.out$Score,session_ref = debateSpeakerData$session_ref,speaker.name = debateSpeakerData$speaker.name,party = as.character(debateSpeakerData$party),title = debateSpeakerData$title,ca_score= ca_file_final$score,dimensions= ca_file_final$dimensions,perc.dim1= ca_file_final$perc.dim1)
wordseine_list[[fileName]] <- new_file
## Prep debate-scaling output
#this has to run per session
#get correct N
Yflat <- as.numeric(wordseine.out$Score)
jVec <- as.integer(as.numeric(wordseine.out$Debate))
iVec <- as.integer(as.character(wordseine.out$Legislator))
iVec <- factor(iVec)
iVec <- droplevels(iVec)
iVec <- as.integer(iVec)
S <- length(Yflat)
N <- length(levels(as.factor(iVec)))
M <- length(levels(as.factor(jVec)))
#add numbers
speech_number <- speech_number + S
debate_number <- debate_number + M
legislator_number <- legislator_number + N
###################################
## Model for Debate-Level Scores ##
###################################
model.script <- '
model{
for (s in 1:S){
Yflat[s] ~ dnorm(alpha[jVec[s]] + beta[jVec[s]]*theta[iVec[s]],tau[iVec[s]])
}
for (i in 1:N){
theta[i] ~ dnorm(0,1)
}
for (j in 1:M){
alpha[j] ~ dnorm(0,4)
beta[j] ~ dnorm(0,4)
}
for (i in 1:N){
tau[i] ~ dgamma(1,1)
}
}
'
if (fullrun){
data=list(N=N,S=S,M=M,Yflat=Yflat,jVec=jVec,iVec=iVec)
model.jags <- jags.model(data,file=textConnection(model.script), #ADAPTED
n.adapt=mcmc.adapt)
update(model.jags, mcmc.burn)
posterior <- jags.samples(model.jags,
c("theta","beta","alpha","tau"),
n.iter=mcmc.sample, thin = mcmc.thin, progress.bar="text")
save(posterior,file="Estimates/WordShoalUK.Rdata")
} else {
load("Estimates/WordShoalUK.Rdata")
}
############################
## Quantities of Interest ##
############################
polarity.fix <- -1*sign(apply(posterior$theta,1,mean)[2])
posterior$theta <- posterior$theta* polarity.fix
posterior$beta <- posterior$beta* polarity.fix
speakerIDs <- as.numeric(levels(wordseine.out$Legislator))
theta.est <- apply(posterior$theta,1,mean)
theta.ci <- apply(posterior$theta,1,quantile,c(0.025,0.975))
theta.prec <- apply(posterior$theta,1,var)^(-1)
beta.est <- apply(posterior$beta,1,mean)
tau.est <- apply(posterior$tau,1,mean)
tau.ci <- apply(posterior$tau,1,quantile,c(0.025,0.975))
labels <- data.frame(wordseine.out$Legislator,debateSpeakerData$speaker.name,debateSpeakerData$session,as.character(debateSpeakerData$party))
colnames(labels) <- c("legislator","speaker.name","session","party")
labels <- labels[!duplicated(labels$legislator),]
final_file <- cbind(labels,theta.est,theta.ci[1,],theta.ci[2,],theta.prec,tau.est,tau.ci[1,],tau.ci[2,])
colnames(final_file) <- cbind("speakerIDs","speaker.name","session_ref","party","theta.est","thetaci2.5","thetaci97.5","theta.prec","tau.est","tau.ci2.5","tau.ci97.5")
all_results[[fileName]] <- final_file
}
print(paste("Total speeches", speech_number,sep=" "))
print(paste("Total debates", debate_number,sep=" "))
print(paste("Total legislators", legislator_number,sep=" "))
#unlist and write out
final_wordseine_results <- do.call(rbind.data.frame,wordseine_list)
write.csv(final_wordseine_results,"UK_wordfish_estimates_ps2.csv")
final_results <- do.call(rbind.data.frame, all_results)
write.csv(final_results,"UK_wordshoal_ps2.csv")
}
}
#=================================
#First version: 5th September 2017
#This version: 5th June 2018
#Author: Niels Goet
#Replication material for "Measuring Polarisation with Text Analysis: Evidence from the UK House of Commons, 1811-2015"
#=================================
#this script takes out members of any party when there is only one member of that party making an intervention in a debate.
#Prior to running this code
#download gfortran from  http://gcc.gnu.org/wiki/GFortranBinaries#MacOS and install (for a useful guide, see https://thecoatlessprofessor.com/programming/rcpp-rcpparmadillo-and-os-x-mavericks--lgfortran-and--lquadmath-error/)
#for jags installation instructions, see http://courses.education.illinois.edu/edpsy590ca/Lectures/5%20MCMC/jags_installation_manual.pdf
#install jags via homebrew: brew install jags
#install.packages("ca")
library(ca)
#install.packages("reshape")
library(reshape)
#install.packages("reshape2")
library(reshape2)
#install.packages("Hmisc")
library(Hmisc)
#create incrementer
inc <- function(x)
{
eval.parent(substitute(x <- x + 1))
}
dataPath <- gsub("wordshoal_with_ca_ps.R","",rstudioapi::getSourceEditorContext()$path)
setwd(paste(dataPath,"wfms_ps2",sep=""))
set.seed(42)
fullrun <- TRUE
mcmc.adapt <- 500
mcmc.burn <- 500
mcmc.sample <- 2000
mcmc.thin <- 2
library(rjags)
source("Wordshoal9.R")
##########################################
## Load UK Speech Data  ##
##########################################
#counts
speech_number <- 0
debate_number <- 0
legislator_number <- 0
#create empty_list
all_results <- list()
wordseine_list <- list()
#read in files
library(base)
fileNames <- Sys.glob("*.RData")
for (fileName in 1:length(fileNames)) { #start loop
print(fileNames[fileName])
data.path <- fileNames[fileName]
load(data.path)
################################
## Run Wordfish on all debates, per session ##
################################
#create new index
debateData$debateID <- 1:nrow(debateData)
debateSpeakerData$debateID <- rep(debateData$debateID,data.frame(table(debateSpeakerData$debateID))$Freq)
debateSpeakerData <- debateSpeakerData[order(debateSpeakerData$party),]
debateSpeakerData$Freq <- rep(data.frame(table(debateSpeakerData$party))$Freq,data.frame(table(debateSpeakerData$party))$Freq)
debateSpeakerData <- debateSpeakerData[order(debateSpeakerData$party),]
debateSpeakerData$Freq <- rep(data.frame(table(debateSpeakerData$party))$Freq,data.frame(table(debateSpeakerData$party))$Freq)
#get rid of unmatched
debateSpeakerData <-  debateSpeakerData[which(!(debateSpeakerData$party %in% c("unknown","none"))),]
debateSpeakerData <- debateSpeakerData[order(debateSpeakerData$debateID),]
if(dim(debateSpeakerData)[1] > 0){
rownames(debateSpeakerData) <- 1:nrow(debateSpeakerData)
rownames(speakerData) <- 1:nrow(speakerData)
#ensure debateData is limited to remaining debates
debateData <- debateData[which(debateData$debateID %in% debateSpeakerData$debateID),]
rownames(debateData) <- 1:nrow(debateData)
speakerData <- speakerData[which(speakerData$speakerID %in% debateSpeakerData$speakerID),]
rownames(speakerData) <- 1:nrow(speakerData)
####################
#take out speakers
####################
speakerWFM.byDebate <- speakerWFM.byDebate[debateData$debateID]
#first order the debateSpeakerData
debateSpeakerData <- debateSpeakerData[order(debateSpeakerData$debateID),]
debateData <- debateData[order(debateData$debateID),]
#now create list
debateSpeakerDataList <- split(debateSpeakerData, debateSpeakerData$debateID)
speakerWFM.byDebate.temp <- list()
#check the number of individual contributions per party label in each debate
for(i in 1:length(debateSpeakerDataList)){
temp <- debateSpeakerDataList[[i]]
temp_wfm <- speakerWFM.byDebate[[i]]
temp$Freq2 <- rep(data.frame(table(temp$party))$Freq,data.frame(table(temp$party))$Freq)
######################################
#set number of times a party members should speak to be included
#####################################
temp$share <- temp$Freq2/nrow(temp)
temp <- temp[temp$share > .19,] #more than once in debate
temp_wfm2 <- temp_wfm[as.numeric(rownames(temp_wfm)) %in% temp$speakerID,]
#guard against SVD error
rowTotals   <- apply(temp_wfm2 , 1, sum) #Find the sum of words in each Document
temp_wfm2   		<- temp_wfm2[rowTotals> 0, ]
if(!is.null(dim(temp_wfm2))){
#deal with duplicates
temp_wfm2 <- temp_wfm2[!duplicated(rownames(temp_wfm2)),]
if(!is.null(dim(temp_wfm2))){
#deal with non-zero entries of words
temp_wfm2 <- temp_wfm2[,colSums(temp_wfm2)>0]
if(length(unique(temp$party))>1 & nrow(temp) > 4){
debateSpeakerDataList[[i]] <- temp
speakerWFM.byDebate.temp[[i]] <- temp_wfm2
}
}
}
}
if(length(speakerWFM.byDebate.temp)>0){
#get rid of NULL values
speakerWFM.byDebate <- speakerWFM.byDebate.temp[!(sapply(speakerWFM.byDebate.temp,is.null))]
debateSpeakerDataList <- debateSpeakerDataList[!(sapply(speakerWFM.byDebate.temp,is.null))]
debateSpeakerDataList  <- debateSpeakerDataList[1:length(speakerWFM.byDebate)]
#########################
#now check the debateSpeakerList
debateSpeakerDataList2 <- list()
for(i in 1:length(speakerWFM.byDebate)){
checkNames <- rownames(speakerWFM.byDebate[[i]])
temp <- debateSpeakerDataList[[i]][debateSpeakerDataList[[i]]$speakerID %in% as.numeric(checkNames),]
temp <- temp[!duplicated(temp$speakerID),]
debateSpeakerDataList2[[i]] <- temp
}
#############
#now create debateSpeakerData dataframe
############
library(plyr)
debateSpeakerData <- ldply(debateSpeakerDataList2, data.frame)
#reset datasets
debateData <- debateData[which(debateData$debateID %in% debateSpeakerData$debateID),]
speakerData <- speakerData[which(speakerData$speakerID %in% debateSpeakerData$speakerID),]
rownames(speakerData) <- 1:nrow(speakerData)
#repair number of speakers
debateData$speakersN <- data.frame(table(debateSpeakerData$debateID))$Freq
debateSpeakerData$speakersN <- rep(data.frame(table(debateSpeakerData$debateID))$Freq,data.frame(table(debateSpeakerData$debateID))$Freq)
debateData <- debateData[which(debateData$debateID %in% debateSpeakerData$debateID),]
#rownames(debateData) <- 1:nrow(debateData)
speakerData <- speakerData[which(speakerData$speakerID %in% debateSpeakerData$speakerID),]
rownames(speakerData) <- 1:nrow(speakerData)
###############
if (fullrun){
#create necessary docs
wordseine.tmp <- wordseine(speakerWFM.byDebate)
wordfish.details <- wordseine.tmp$wordfish.details
wordseine.out <- wordseine.tmp$debate.scaling.results
save(wordseine.out,file="Estimates/WordSeineUK.Rdata")
save(wordfish.details,file="Estimates/WordfishUK.Rdata")
#############################
#apply CA
#############################
ca_files <- list()
for(wfm in 1:length(speakerWFM.byDebate)){
wcdata <- speakerWFM.byDebate[[wfm]]
ca_results  <- ca(t(wcdata))
ca_file  <- data.frame(score=ca_results$colcoord[,1])
#ca_file$score <- scale(ca_file$score,center=T,scale=T) # rescale with mean = center, variance = 1
s <- dim(t(wcdata))[2]
#check whether the first dimension accounts for more than what we would expect at random
random_accounts <- 100/(s-1)
singular_values <- ca_results$sv
inertia <- singular_values^2
pct <- 100*inertia/sum(inertia)
actual_account <- ca_results
x <- 0
for (p in pct){
if (p > random_accounts){
inc(x)
}}
dimensions <- x
perc.dim1 <- pct[1]
ca_file$dimensions <- rep(dimensions,nrow(ca_file))
ca_file$perc.dim1 <- rep(perc.dim1,nrow(ca_file))
ca_files[[wfm]] <- ca_file
}
#############################
#Combine CA and Wordfish results in one file
#############################
} else {
load("Estimates/WordSeineUK.Rdata")
load("Estimates/WordfishUK.Rdata")
}
ca_file_final <- do.call(rbind.data.frame,ca_files)
print(names(wordseine.out))
new_file <- data.frame(debateID = wordseine.out$Debate, Legislator = wordseine.out$Legislator,speaker.name = debateSpeakerData$speaker.name, Score=wordseine.out$Score,session_ref = debateSpeakerData$session_ref,speaker.name = debateSpeakerData$speaker.name,party = as.character(debateSpeakerData$party),title = debateSpeakerData$title,ca_score= ca_file_final$score,dimensions= ca_file_final$dimensions,perc.dim1= ca_file_final$perc.dim1)
wordseine_list[[fileName]] <- new_file
## Prep debate-scaling output
#this has to run per session
#get correct N
Yflat <- as.numeric(wordseine.out$Score)
jVec <- as.integer(as.numeric(wordseine.out$Debate))
iVec <- as.integer(as.character(wordseine.out$Legislator))
iVec <- factor(iVec)
iVec <- droplevels(iVec)
iVec <- as.integer(iVec)
S <- length(Yflat)
N <- length(levels(as.factor(iVec)))
M <- length(levels(as.factor(jVec)))
#add numbers
speech_number <- speech_number + S
debate_number <- debate_number + M
legislator_number <- legislator_number + N
###################################
## Model for Debate-Level Scores ##
###################################
model.script <- '
model{
for (s in 1:S){
Yflat[s] ~ dnorm(alpha[jVec[s]] + beta[jVec[s]]*theta[iVec[s]],tau[iVec[s]])
}
for (i in 1:N){
theta[i] ~ dnorm(0,1)
}
for (j in 1:M){
alpha[j] ~ dnorm(0,4)
beta[j] ~ dnorm(0,4)
}
for (i in 1:N){
tau[i] ~ dgamma(1,1)
}
}
'
if (fullrun){
data=list(N=N,S=S,M=M,Yflat=Yflat,jVec=jVec,iVec=iVec)
model.jags <- jags.model(data,file=textConnection(model.script), #ADAPTED
n.adapt=mcmc.adapt)
update(model.jags, mcmc.burn)
posterior <- jags.samples(model.jags,
c("theta","beta","alpha","tau"),
n.iter=mcmc.sample, thin = mcmc.thin, progress.bar="text")
save(posterior,file="Estimates/WordShoalUK.Rdata")
} else {
load("Estimates/WordShoalUK.Rdata")
}
############################
## Quantities of Interest ##
############################
polarity.fix <- -1*sign(apply(posterior$theta,1,mean)[2])
posterior$theta <- posterior$theta* polarity.fix
posterior$beta <- posterior$beta* polarity.fix
speakerIDs <- as.numeric(levels(wordseine.out$Legislator))
theta.est <- apply(posterior$theta,1,mean)
theta.ci <- apply(posterior$theta,1,quantile,c(0.025,0.975))
theta.prec <- apply(posterior$theta,1,var)^(-1)
beta.est <- apply(posterior$beta,1,mean)
tau.est <- apply(posterior$tau,1,mean)
tau.ci <- apply(posterior$tau,1,quantile,c(0.025,0.975))
labels <- data.frame(wordseine.out$Legislator,debateSpeakerData$speaker.name,debateSpeakerData$session,as.character(debateSpeakerData$party))
colnames(labels) <- c("legislator","speaker.name","session","party")
labels <- labels[!duplicated(labels$legislator),]
final_file <- cbind(labels,theta.est,theta.ci[1,],theta.ci[2,],theta.prec,tau.est,tau.ci[1,],tau.ci[2,])
colnames(final_file) <- cbind("speakerIDs","speaker.name","session_ref","party","theta.est","thetaci2.5","thetaci97.5","theta.prec","tau.est","tau.ci2.5","tau.ci97.5")
all_results[[fileName]] <- final_file
}
print(paste("Total speeches", speech_number,sep=" "))
print(paste("Total debates", debate_number,sep=" "))
print(paste("Total legislators", legislator_number,sep=" "))
#unlist and write out
final_wordseine_results <- do.call(rbind.data.frame,wordseine_list)
write.csv(final_wordseine_results,"UK_wordfish_estimates_ps2.csv")
final_results <- do.call(rbind.data.frame, all_results)
write.csv(final_results,"UK_wordshoal_ps2.csv")
}
}
