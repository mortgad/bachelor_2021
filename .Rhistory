lapply(names(hep2), function(x) shoaling(hep2[[x]]))
# getting theta estimates for each speaker per month
hep <- testfunc(data = df, year_list = c("2019"), party_list = c("Venstre"))
df %>% group_by(id) %>% count(n()) %>% arrange(-n)
df %>% group_by(id) %>% count(n()) %>% arrange(n)
df %>% group_by(Parti) %>% group_by(id) %>% count(n()) %>% arrange(n)
df %>% filter(Parti == "Venstre") %>% group_by(id) %>% count(n()) %>% arrange(n)
count <- df %>% filter(Parti == "Venstre") %>% group_by(id) %>% count(n()) %>% arrange(n)
count[1]
count <- df %>% filter(Parti == "Venstre") %>% group_by(id) %>% count(n()) %>% arrange(n)
View(count)
View(count)
count$n[1]
testfunc <- function(data, year_list, party_list){
if(missing(data)){
cat("Missing data-argument")
} else if(hasArg(year_list) & hasArg(party_list)){
data = data %>% filter(Year %in% year_list & Parti %in% party_list)
} else if(hasArg(party_list)){
data = data %>% filter(Parti %in% party_list)
} else if(hasArg(year_list)){
data = data %>% filter(Year %in% year_list)
}
theta_df <<- data.frame()
# create nested list of dataframes to which the shoal-function is applied
nested = data %>% split(.$month_year_id)
lapply(names(nested), function(x) shoaling(nested[[x]]))
}
rm(theta_df)
# getting theta estimates for each speaker per month
hep <- testfunc(data = df, year_list = c("2019"), party_list = c("Venstre"))
testfunc <- function(data, year_list, party_list){
if(missing(data)){
cat("Missing data-argument")
} else if(hasArg(year_list) & hasArg(party_list)){
data = data %>% filter(Year %in% year_list & Parti %in% party_list)
} else if(hasArg(party_list)){
data = data %>% filter(Parti %in% party_list)
} else if(hasArg(year_list)){
data = data %>% filter(Year %in% year_list)
}
# creating empty df to append to
theta_df <<- data.frame()
# create nested list of dataframes to which the shoal-function is applied
nested = data %>% split(.$month_year_id)
lapply(names(nested), function(x) shoaling(nested[[x]]))
}
# getting theta estimates for each speaker per month for Venstre speakers
hep <- testfunc(data = df, year_list = c("2019"), party_list = c("Venstre", "Socialdemokratiet"))
View(theta_df)
testfunc <- function(data, year_list, party_list){
if(missing(data)){
cat("Missing data-argument")
} else if(hasArg(year_list) & hasArg(party_list)){
data = data %>% filter(Year %in% year_list & Parti %in% party_list)
} else if(hasArg(party_list)){
data = data %>% filter(Parti %in% party_list)
} else if(hasArg(year_list)){
data = data %>% filter(Year %in% year_list)
}
# creating empty df to append to
theta_df <<- data.frame()
# create nested list of dataframes to which the shoal-function is applied
nested = data %>% split(.$month_year_id)
lapply(names(nested), function(x) shoaling(nested[[x]]))
filename = paste0("./data/wordshoal_results/wordshoal_estimates_", min(year_list), "_", max(year_list), ".csv")
write_csv(theta_df, filename)
}
# getting theta estimates for each speaker per month for Venstre speakers
hep <- testfunc(data = df, year_list = c("2019"), party_list = c("Socialdemokratiet"))
# getting theta estimates for each speaker per month for Venstre speakers
hep <- testfunc(data = df, year_list = c("2019"), party_list = c("Socialdemokratiet", "Radikale Venstre"))
# getting theta estimates for each speaker per month for Venstre speakers
hep <- testfunc(data = df, year_list = c("2019"), party_list = c("Socialdemokratiet", "Venstre"))
get_theta <- function(data){
corpus = quanteda::corpus(data)
dfm <- dfm(tokens(corpus), remove_punct = TRUE, ignoredFeatures = stopwords("danish")) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfm, groups = docvars(corpus, "id"),
authors = docvars(corpus, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpus),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
theta_df <<- rbind(theta_df, fitdf)
}
testfunc <- function(data, year_list, party_list){
# subsetting data frame based on arguments
if(missing(data)){
cat("Missing data-argument")
} else if(hasArg(year_list) & hasArg(party_list)){
data = data %>% filter(Year %in% year_list & Parti %in% party_list)
} else if(hasArg(party_list)){
data = data %>% filter(Parti %in% party_list)
} else if(hasArg(year_list)){
data = data %>% filter(Year %in% year_list)
}
# creating empty df to append to
theta_df <<- data.frame()
# create nested list of dataframes to which the shoal-function is applied
nested = data %>% split(.$month_year_id)
lapply(names(nested), function(x) get_theta(nested[[x]]))
filename = paste0("./data/wordshoal_results/wordshoal_estimates_", min(year_list), "_", max(year_list), ".csv")
write_csv(theta_df, filename)
}
# Load results dataframe
results <- read_csv("./data/agg_results_2009_2014.csv") %>%
# Creating date variable
mutate(
Date = str_replace(month_year_id, "_", "-"),
Date = as.Date(paste0(Date, "-01"))
)
# loading packages
pacman::p_load(tidyverse,stringdist, overlapping, lubridate)
# Load results dataframe
results <- read_csv("./data/agg_results_2009_2014.csv") %>%
# Creating date variable
mutate(
Date = str_replace(month_year_id, "_", "-"),
Date = as.Date(paste0(Date, "-01"))
)
results %>%  group_by(Parti, Date) %>% summarise(mean = mean(difference_score)) %>% ungroup() %>% group_by(Date) %>% summarise(mean = mean(mean)) %>% ungroup() %>%
ggplot()+
aes(x = Date, y = mean)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])+
geom_smooth(method = "lm", alpha = 0.1, color = wesanderson::wes_palette("Darjeeling1")[1], size = 0.5)+
ylim(0, 1)+
labs(x = "Time",y = "Mean difference score", title = "Wordshoal - Level of polarization in Folketinget")
View(results)
View(results)
?overlap
# Loading the results
csv_files = list.files(pattern="*.csv", path = "data/wordshoal_results/", full.names = T)
df = map_df(csv_files, read_csv)
df$time <- as.Date(paste(year(df$Date), month(df$Date), "01", sep = "-"))
df <- df %>% mutate(
Parti = ifelse(Parti == "Det Radikale Venstre","Radikale Venstre", Parti)
)
subset <- df %>% filter(month_year_id == 2011_5) %>% group_by(Parti) %>% filter(n() > 1) %>% ungroup()
subset <- df %>% filter(month_year_id == "2011_5") %>% group_by(Parti) %>% filter(n() > 1) %>% ungroup()
parties <- unique(subset$Parti)
wide <- subset %>% pivot_wider(names_from = Parti, values_from = theta)
View(wide)
list <- list()
# Adding the parties to the list
for(party in parties){
list <- append(list,na.omit(select(wide, party)))
}
View(list)
list[[2]]
what <- list[[2]]
View(what)
overlaps <- overlap(list)
# Adding the parties to the list
for(party in parties){
list <- append(list,na.omit(select(wide, party)))
}
list <- list()
# Adding the parties to the list
for(party in parties){
list <- append(list,na.omit(select(wide, party)))
}
overlaps <- overlap(list)
# Load results dataframe
results <- read_csv("./data/agg_results_2009_2014.csv") %>%
# Creating date variable
mutate(
Date = str_replace(month_year_id, "_", "-"),
Date = as.Date(paste0(Date, "-01"))
)
######## Preprocessing #########3
# Agregating results into a single data frame - VERY MESSY i know
agg <- results %>% group_by(Parti, Date) %>% arrange(-overlap_score, .by_group = TRUE) %>% slice(1:3) %>%
summarise(overlap_score = mean(overlap_score),
difference_score = mean(difference_score))
View(agg)
agg <- left_join(x = agg, y = results %>% select(c(Parti, Date, mean_theta, sd_theta)), by = c("Parti" = "Parti", "Date" = "Date")) %>% group_by(Parti, Date) %>% slice(1) %>% ungroup()
agg <- left_join(x = agg, y = results %>% select(c(Parti, Date, mean_theta, sd_theta)), by = c("Parti" = "Parti", "Date" = "Date")) %>% group_by(Parti, Date) %>% slice(1) %>% ungroup()
# Adding a lag column for the predictors - difference_score and sd_theta
agg <- agg %>% mutate(
lag_difference_score = lag(difference_score ),
lag_sd_theta = lag(sd_theta)
)
View(agg)
######## Preprocessing #########3
# Agregating results into a single data frame - VERY MESSY i know
agg <- results %>% group_by(Parti, Date) %>% arrange(-overlap_score, .by_group = TRUE) %>% slice(1:3) %>%
summarise(overlap_score = mean(overlap_score),
difference_score = mean(difference_score))
View(agg)
?left_join
agg <- left_join(x = agg, y = results %>% select(c(Parti, Date, mean_theta, sd_theta)), by = c("Parti" = "Parti", "Date" = "Date")) %>% group_by(Parti, Date) %>% slice(1) %>% ungroup()
View(agg)
# Adding a lag column for the predictors - difference_score and sd_theta
agg <- agg %>% mutate(
lag_difference_score = lag(difference_score ),
lag_sd_theta = lag(sd_theta)
)
View(agg)
# Modelling with lmer!!!
pacman::p_load(lme4)
#  m1: InclusionSD_t2 ~ 1 + InclusionSD_t1 + Overlapping_t1 + (1 + InclusionSD_t1 + Overlapping_t1 | Party)
m1 <- lm(sd_theta ~ 1 + lag_sd_theta + lag_difference_score, data = agg)
summary(m1)
m2 <- lmer(sd_theta ~ 1 + lag_sd_theta + lag_difference_score + (1 + lag_sd_theta + lag_difference_score | Parti), data = agg)
m2 <- lmer(sd_theta ~ 1 + lag_sd_theta + lag_difference_score + (1 + lag_sd_theta + lag_difference_score | Parti), data = agg)
summary(m2)
summary(m2)
ft_members = read_delim("./data/metadata_for_scraping/folketing_members.csv", ";", col_names =FALSE, col_types = cols())
View(ft_members)
names(ft_members) = c("Name", "Parti", "Year")
ft_members = ft_members %>%
## mutate(Parti = str_extract(Parti, "\\w+") ) %>%
group_by(Name, Parti) %>%
summarise(Year = min(Year)) %>% ungroup()
View(ft_members)
ft_members = read_delim("./data/metadata_for_scraping/folketing_members.csv", ";", col_names =FALSE, col_types = cols())
names(ft_members) = c("Name", "Parti", "Year")
ft_members_copy = ft_members
View(ft_members)
?group_by
ft_members = ft_members %>%
## mutate(Parti = str_extract(Parti, "\\w+") ) %>%
group_by(Name, Parti) %>%
summarise(Year = min(Year)) %>% ungroup()
View(ft_members)
View(ft_members_copy)
ft_members = read_delim("./data/metadata_for_scraping/folketing_members.csv", ";", col_names =FALSE, col_types = cols())
names(ft_members) = c("Name", "Parti", "Year")
ft_members = ft_members %>%
## mutate(Parti = str_extract(Parti, "\\w+") ) %>%
group_by(Name, Parti) %>%
summarise(Year = min(Year)) #%>% ungroup()
ft_members = read_delim("./data/metadata_for_scraping/folketing_members.csv", ";", col_names =FALSE, col_types = cols())
names(ft_members) = c("Name", "Parti", "Year")
ft_members = ft_members %>%
## mutate(Parti = str_extract(Parti, "\\w+") ) %>%
group_by(Name, Parti) %>%
summarise(Year = min(Year)) %>% ungroup()
View(ft_members_copy)
?tidyr::expand
ft_members = ft_members %>%
tidyr::expand(Name, Year = min(Year):max(Year)) %>%
#left_join(ft_members, by = c("Name", "Year")) %>%
#arrange(Name, Year) %>%
#fill(Parti) %>%
#filter(complete.cases(Parti))
data3 = data2 %>%
mutate(Year = year(Date)) %>%
left_join(ft_members, by = c("Name", "Year")) %>%
mutate(Parti = ifelse(is.na(Parti.x), Parti.y, Parti.x)) %>%
select(-Parti.x, -Parti.y)
ft_members = ft_members %>%
tidyr::expand(Name, Year = min(Year):max(Year)) %>%
#left_join(ft_members, by = c("Name", "Year")) %>%
#arrange(Name, Year) %>%
#fill(Parti) %>%
#filter(complete.cases(Parti))
data3 = data2 %>%
mutate(Year = year(Date)) %>%
left_join(ft_members, by = c("Name", "Year")) %>%
mutate(Parti = ifelse(is.na(Parti.x), Parti.y, Parti.x)) %>%
select(-Parti.x, -Parti.y)
data3 = data2 %>%
mutate(Year = year(Date)) %>%
left_join(ft_members, by = c("Name", "Year")) %>%
mutate(Parti = ifelse(is.na(Parti.x), Parti.y, Parti.x)) %>%
select(-Parti.x, -Parti.y)
ft_members = ft_members %>%
tidyr::expand(Name, Year = min(Year):max(Year)) #%>%
View(ft_members)
data3 = data2 %>%
mutate(Year = year(Date)) %>%
left_join(ft_members, by = c("Name", "Year")) %>%
mutate(Parti = ifelse(is.na(Parti.x), Parti.y, Parti.x)) %>%
select(-Parti.x, -Parti.y)
ft_members = ft_members %>%
tidyr::expand(Name, Year = min(Year):max(Year)) %>%
left_join(ft_members, by = c("Name", "Year")) #%>%
ft_members = read_delim("./data/metadata_for_scraping/folketing_members.csv", ";", col_names =FALSE, col_types = cols())
names(ft_members) = c("Name", "Parti", "Year")
ft_members_copy = ft_members
ft_members = ft_members %>%
## mutate(Parti = str_extract(Parti, "\\w+") ) %>%
group_by(Name, Parti) %>%
summarise(Year = min(Year)) %>% ungroup()
ft_members = ft_members %>%
tidyr::expand(Name, Year = min(Year):max(Year)) %>%
left_join(ft_members, by = c("Name", "Year")) #%>%
View(ft_members)
View(ft_members_copy)
arrange(Name, Year) %>%
fill(Parti) %>%
filter(complete.cases(Parti))
ft_members = ft_members %>%
tidyr::expand(Name, Year = min(Year):max(Year)) %>%
left_join(ft_members, by = c("Name", "Year")) %>%
arrange(Name, Year) %>%
fill(Parti) %>%
filter(complete.cases(Parti))
View(ft_members)
### Hardcoding the last names that are missing
hardcoded_names <- data3 %>%
filter(is.na(Parti)) %>%
distinct(Name, Year) %>%
arrange(Name, Year)
library(tidyverse)
library(lubridate)
# library(udpipe)
library(stopwords)
library(groupdata2)
library(fuzzyjoin)
title_re_paren = "(?<=\\().*(?=\\))"
title_re_noparen = ".*"
name_re = "[\\w\\s-\\.]+"
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) %>%
select(-PDF, -X6)
tidy_text <- function(filename) {
cat(paste0("[ ] Tidying ", filename, "\n"))
d = read_delim(filename, delim = ";", col_types = cols()) %>%
filter(complete.cases(reason))
if (nrow(d) < 3) return(data.frame(NA))
if (!any(str_detect(d$reason, "name"))) return (data.frame(NA))
d = d %>%
filter(split > 0) %>%
mutate(value = case_when(
reason == "title_name" ~ ifelse(
str_detect(value, "\\(|\\)"),
str_extract(value, title_re_paren),
str_extract(value, title_re_noparen)),
reason == "name_party" ~ str_extract(value, name_re),
reason == "Time" ~ value),
reason = ifelse(reason == "Time", "Time", "Name"),
value = trimws(value)) %>%
spread(reason, value) %>%
select(-split)
if ("Time" %in% colnames(d)) {
d = d %>%
fill(Time, Name) %>%
mutate(Time = hm(Time))
} else {
d$Time = hm(NA)
}
d = d %>%
filter(complete.cases(text), complete.cases(Name)) %>%
mutate(id = tools::file_path_sans_ext(basename(filename))) %>%
as_data_frame()
return(d)
}
files = list.files("./data/segmented", "*.txt", full.names = TRUE)
data = map_dfr(files, tidy_text) %>%
## bind_rows() %>%
right_join(meta, by = "id") %>%
mutate(Date = parse_date_time(str_c(Dato, Time, sep = " "),
orders = c("dmy HMS", "dmy MS", "dmy S"))) %>%
filter(complete.cases(Date)) %>%
arrange(Date) %>%
mutate(speaker_id = ifelse(lag(Name) != Name, 1, 0) %>%
coalesce(0) %>%
cumsum()) %>%
group_by(Name, id, Samling, Nr, Titel, Dato, speaker_id) %>%
summarise(text = str_c(text, collapse = " "),
Date = min(Date)) %>% ungroup() %>%
mutate(doc_id = as.character(as.integer(as.factor(str_c(speaker_id, Name, Date))))) %>%
ungroup()
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) %>%
select(-PDF, -X6)
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) %>%
select(-PDF, -X6)
library(tidyverse)
library(lubridate)
# library(udpipe)
library(stopwords)
library(groupdata2)
library(fuzzyjoin)
title_re_paren = "(?<=\\().*(?=\\))"
title_re_noparen = ".*"
name_re = "[\\w\\s-\\.]+"
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) %>%
select(-PDF, -X6)
tidy_text <- function(filename) {
cat(paste0("[ ] Tidying ", filename, "\n"))
d = read_delim(filename, delim = ";", col_types = cols()) %>%
filter(complete.cases(reason))
if (nrow(d) < 3) return(data.frame(NA))
if (!any(str_detect(d$reason, "name"))) return (data.frame(NA))
d = d %>%
filter(split > 0) %>%
mutate(value = case_when(
reason == "title_name" ~ ifelse(
str_detect(value, "\\(|\\)"),
str_extract(value, title_re_paren),
str_extract(value, title_re_noparen)),
reason == "name_party" ~ str_extract(value, name_re),
reason == "Time" ~ value),
reason = ifelse(reason == "Time", "Time", "Name"),
value = trimws(value)) %>%
spread(reason, value) %>%
select(-split)
if ("Time" %in% colnames(d)) {
d = d %>%
fill(Time, Name) %>%
mutate(Time = hm(Time))
} else {
d$Time = hm(NA)
}
d = d %>%
filter(complete.cases(text), complete.cases(Name)) %>%
mutate(id = tools::file_path_sans_ext(basename(filename))) %>%
as_data_frame()
return(d)
}
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) #%>%
View(meta)
# select(-PDF, -X6) this was Malthes, but column X6 does not exist???
select(-PDF, -...6)
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) #%>%
View(meta)
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) %>%
# select(-PDF, -X6) this was Malthes, but column X6 does not exist???
select(-PDF, -...6)
View(meta)
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) %>%
# select(-PDF, -X6) this was Malthes, but column X6 does not exist???
select(-PDF, -...6) # idk why column name has changed
tidy_text <- function(filename) {
cat(paste0("[ ] Tidying ", filename, "\n"))
d = read_delim(filename, delim = ";", col_types = cols()) %>%
filter(complete.cases(reason))
if (nrow(d) < 3) return(data.frame(NA))
if (!any(str_detect(d$reason, "name"))) return (data.frame(NA))
d = d %>%
filter(split > 0) %>%
mutate(value = case_when(
reason == "title_name" ~ ifelse(
str_detect(value, "\\(|\\)"),
str_extract(value, title_re_paren),
str_extract(value, title_re_noparen)),
reason == "name_party" ~ str_extract(value, name_re),
reason == "Time" ~ value),
reason = ifelse(reason == "Time", "Time", "Name"),
value = trimws(value)) %>%
spread(reason, value) %>%
select(-split)
if ("Time" %in% colnames(d)) {
d = d %>%
fill(Time, Name) %>%
mutate(Time = hm(Time))
} else {
d$Time = hm(NA)
}
d = d %>%
filter(complete.cases(text), complete.cases(Name)) %>%
mutate(id = tools::file_path_sans_ext(basename(filename))) %>%
as_data_frame()
return(d)
}
test_ft = ft_members_copy %>%
mutate(Year = map(Year, ~ .x:(.x+3))) %>%
unnest()
View(test_ft)
View(ft_members_copy)
weird_names = filter(data3, is.na(Parti)) %>%
distinct(Name, Year) %>%
arrange(Name, Year)
?fuzzy_join
periods = tribble(~Period,     ~StartDate,
"1953-1957", "22-09-1953",
"1957-1960", "14-05-1957",
"1960-1964", "15-11-1960",
"1964-1966", "22-09-1964",
"1966-1968", "22-11-1966",
"1968-1971", "23-01-1968",
"1971-1973", "21-09-1971",
"1973-1975", "04-12-1973",
"1975-1977", "09-01-1975",
"1977-1979", "15-02-1977",
"1979-1981", "23-10-1979",
"1981-1984", "08-12-1981",
"1984-1987", "10-01-1984",
"1987-1988", "08-09-1987",
"1988-1990", "10-05-1988",
"1990-1994", "12-12-1990",
"1994-1998", "21-09-1994",
"1998-2001", "11-03-1998",
"2001-2005", "20-11-2001",
"2005-2007", "08-02-2005",
"2007-2011", "24-10-2007",
"2011-2015", "15-09-2011",
"2015-2019", "18-06-2015",
"2019-"    , "05-06-2019") %>%
mutate(StartDate = dmy(StartDate))
View(periods)
nrow(periods):1
