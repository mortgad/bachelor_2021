# Running the model
m1 <- brm(
formula = f1,
data = na.omit(agg),
family = gaussian(),
prior = prior_m1,
sample_prior = T,
chains = 1,
cores = 1,
backend = "cmdstanr"#,
#file = here("models", "m1")
)
# Posterior predictive check
pp_check(m1, nsamples = 100)
# Diagnostics
# Summary output
print(m1)
View(agg)
sd(agg$mean_theta)
View(means)
View(agg)
sd(agg$sd_theta)
View(means)
sd(agg$sd_theta)
sd(means$mean_of_mean)
sd(means$sd_of_mean)
View(agg)
hejsa <- agg %>% group_by(Parti, Date) %>% summarise(mean = mean(sd_theta))
View(hejsa)
View(hejsa)
hejsa <- agg %>% group_by(Parti, Date) %>% summarise(n = n())
View(hejsa)
agg %>% group_by(Parti, Date) %>% summarise(n())
hejsa <- agg %>% group_by(Parti, Date) %>% summarise(sd = sd(sd_theta))
View(hejsa)
hejsa <- agg %>% group_by(Parti) %>% summarise(sd = sd(sd_theta))
View(hejsa)
hejsa <- agg %>% group_by(Parti) %>% summarise(mean = mean(sd_theta)) %>% summarise(mean_of_mean = mean(mean))
View(hejsa)
# Finding prior for random intercept
means <- agg %>% group_by(Parti, Date) %>% summarise(mean = mean(sd_theta), # does not make sense to me, group size equals 1 for all groups
sd = sd(sd_theta)) %>% summarise(mean_of_mean = mean(mean), # what about sd(sd_theta)?
sd_of_mean = sd(mean)) # we dont seem to use sd of theta
View(means)
hejsa <- agg %>% group_by(Parti) %>% summarise(mean = mean(sd_theta)) %>% summarise(mean_of_mean = mean(mean),
sd_of_mean = sd(mean))
View(hejsa)
hejsa <- agg %>% group_by(Parti) %>% summarise(mean = mean(sd_theta),
sd = sd(sd_theta)) %>% summarise(mean_of_mean = mean(mean),
mean_of_sd = sd(mean))
View(hejsa)
hejsa <- agg %>% group_by(Parti) %>% summarise(mean = mean(sd_theta),
sd = sd(sd_theta)) %>% summarise(mean_of_mean = mean(mean),
mean_of_sd = mean(sd))
View(hejsa)
View(agg)
get_prior(f1, data = agg)
View(agg)
View(agg)
agg <- agg %>% na.omit() %>% filter(mean_theta != 0 & sd_theta != 0)
mean(log(agg$Inclusion))
sd(log(agg$Inclusion))
sd(log(agg$Inclusion))
logmeans <- agg %>%
mutate(log_inclusion = log(Inclusion)) %>%
group_by(Parti) %>%
summarise(mean = mean(log_inclusion),
sd = sd(log_inclusion)) %>%
summarise(mean_of_means = mean(mean),
mean_of_sd = mean(sd))
View(logmeans)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
data <- read_csv("./data/folketinget_2009_2021_raw.csv")
nrows(data)
??nrows
nrow(data)
length(unique(data[["Year"]]))
sample <- data %>% group_by(Year) %>% sample_n(round(100/length(unique(data[["Year"]]))))
View(sample)
sample <- data %>% group_by(Year) %>% sample_n(5)
View(sample)
sample <- data %>% group_by(Year) %>% sample_n(round(100/length(unique(data[["Year"]]))))
# sa
set.seed(123)
sample <- data %>% group_by(Year) %>% sample_n(round(100/length(unique(data[["Year"]]))))
View(sample)
# sa
set.seed(124)
sample <- data %>% group_by(Year) %>% sample_n(round(100/length(unique(data[["Year"]]))))
# sa
set.seed(123)
sample <- data %>% group_by(Year) %>% sample_n(round(100/length(unique(data[["Year"]]))))
sample <- data %>% group_by(Year) %>% sample_n(round(100/length(unique(data[["Year"]])))) %>% select(id, text)
View(sample)
sample <- data %>% group_by(Year) %>% sample_n(round(100/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text)
View(sample)
# sample ~200 values across different years
set.seed(123)
sample <- data %>% group_by(Year) %>% sample_n(round(200/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text)
View(sample)
# packages
library(tidyverse, dplyr, wakefield)
answer(n, x = c("No", "Yes"), prob = NULL, name = "Answer")
# packages
install.packages(wakefield)
# packages
pacman::p_load_gh("trinker/wakefield")
answer(n, x = c("No", "Yes"), prob = NULL, name = "Answer")
answer(n, x = c("No", "Yes"), prob = NULL, name = "Answer", size = 5)
answer(n, x = c("No", "Yes"), prob = NULL, name = "Answer", n = 5)
answer(n = 5, x = c("No", "Yes"), prob = NULL, name = "Answer")
answer(n = 5, x = c("No", "Yes"), prob = 1, name = "Answer")
answer(n = 5, x = c("No", "Yes"), prob = 1.0, name = "Answer")
answer(n = 5, x = c("No", "Yes"), prob = 0.2, name = "Answer")
?answer
answer(n = 5, x = c("No", "Yes"), prob = c(1,1,1,1,1), name = "Answer")
answer(n = 100, x = c("No", "Yes"), prob = NULL, name = "Answer")
sample$correct <- answer(n = nrow(sample), x = c("No", "Yes"), prob = NULL, name = "Answer")
View(sample)
?rep
sample$correct <- rep(x = (1,2), times = nrow(sample))
n <- nrow(samples) # sample size
sample(c(0,1), replace=TRUE, size=samples)
samples <- data %>% group_by(Year) %>% sample_n(round(200/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text)
n <- nrow(samples) # sample size
sample(c(0,1), replace=TRUE, size=samples)
sample(c(0,1), replace=TRUE, size=n)
samples$correct <- sample(c(0,1), replace=TRUE, size=n)
sum(samples$correct)/nrow(samples)
View(samples)
morten <- sample_n(samples, nrow(samples)/2)
?sample_n
samples %>% sample_n(10)
samples %>% sample_n(10) %>% mutate(who = "Morten")
morten <- samples %>% sample_n(10) %>% mutate(who = "Morten")
View(morten)
morten <- samples %>% sample_n(50) %>% mutate(who = "Morten")
morten <- samples %>% sample_n(nrow(samples)/2) %>% mutate(who = "Morten")
samples$who <- ifelse(id %in% morten$id, "Morten", "Gustav")
View(samples)
morten$id
morten <- samples %>% sample_n(nrow(samples)/2) %>% mutate(who = "Morten") %>% as.list(id)
samples$who <- ifelse(id %in% morten$id, "Morten", "Gustav")
ifelse(id %in% morten$id, "Morten", "Gustav")
ifelse(samples$id %in% morten$id, "Morten", "Gustav")
# sample ~200 values across different years
set.seed(123)
samples <- data %>% group_by(Year) %>% sample_n(round(200/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text)
morten <- samples %>% sample_n(nrow(samples)/2) %>% mutate(who = "Morten")
samples$who <- ifelse(samples$id %in% morten$id, "Morten", "Gustav")
samples$who <- ifelse(samples$id %in% (samples %>% sample_n(nrow(samples)/2)) %>% .id, "Morten", "Gustav")
samples$who <- ifelse(samples$id %in% (samples %>% sample_n(nrow(samples)/2)) %>% as.list(id)), "Morten", "Gustav")
samples$who <- ifelse(samples$id %in% (sample_n(samples, nrow(samples)/2) %>% as.list(id)), "Morten", "Gustav")
View(samples)
samples$who <- ifelse(samples$id %in% (sample_n(samples$id, nrow(samples)/2)), "Morten", "Gustav")
View(samples)
samples$who <- ifelse(samples$id %in% as.list((sample_n(samples$id, nrow(samples)/2))), "Morten", "Gustav")
samples$who <- ifelse(samples$id %in% as.tibble((sample_n(samples$id, nrow(samples)/2))), "Morten", "Gustav")
samples$who <- ifelse(samples$id %in% as.data.frame((sample_n(samples$id, nrow(samples)/2))), "Morten", "Gustav")
sample_n(samples$id, nrow(samples)/2)
sample(samples$id, nrow(samples)/2)
samples$who <- ifelse(samples$id %in% ((sample(samples$id, nrow(samples)/2))), "Morten", "Gustav")
View(samples)
length(samples$who == "Morten")
length(samples$who == "Gustav")
length(filter(samples$who == "Gustav"))
samples %>% group_by(who) %>% count(n())
samples %>% group_by(who) %>% count()
# sample ~200 values across different years
set.seed(123)
samples <- data %>% group_by(Year) %>% sample_n(round(200/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text)
# assign rater
samples$who <- ifelse(samples$id %in% ((sample(samples$id, nrow(samples)/2))), "Morten", "Gustav")
samples %>% group_by(who) %>% count()
# sample ~200 values across different years
set.seed(124)
samples <- data %>% group_by(Year) %>% sample_n(round(200/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text)
# assign rater
samples$who <- ifelse(samples$id %in% ((sample(samples$id, nrow(samples)/2))), "Morten", "Gustav")
samples %>% group_by(who) %>% count()
length((sample(samples$id, nrow(samples)/2)))
samples <- data %>% group_by(Year) %>% sample_n(round(200/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text, doc_id)
# assign rater
samples$who <- ifelse(samples$id %in% ((sample(samples$doc_id, nrow(samples)/2))), "Morten", "Gustav")
samples %>% group_by(who) %>% count()
# assign rater
samples$who <- ifelse(samples$doc_id %in% ((sample(samples$doc_id, nrow(samples)/2))), "Morten", "Gustav")
samples %>% group_by(who) %>% count()
View(samples)
paste0(n, " hej")
# sample ~200 values across different years
set.seed(124)
samples <- data %>% group_by(Year) %>% sample_n(round(200/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text, doc_id, year)
samples <- data %>% group_by(Year) %>% sample_n(round(200/length(unique(data[["Year"]])))) %>% ungroup() %>% select(id, text, doc_id, Year)
# assign rater
samples$who <- ifelse(samples$doc_id %in% ((sample(samples$doc_id, nrow(samples)/2))), "Morten", "Gustav")
samples %>% group_by(who) %>% count()
paste0(nrows(samples), "_", max(samples$Year, "_", min(samples$Year)))
paste0(nrow(samples), "_", max(samples$Year, "_", min(samples$Year)))
View(samples)
min(samples$Year)
paste0(nrow(samples), "_", max(samples$Year), "_", min(samples$Year)))
paste0(nrow(samples), "_", max(samples$Year), "_", min(samples$Year))
paste0(nrow(samples), "_", min(samples$Year), "_", max(samples$Year))
paste0("samples", nrow(samples), "_", min(samples$Year), "_", max(samples$Year))
paste0("samples_", nrow(samples), "_", min(samples$Year), "_", max(samples$Year))
paste0(nrow(samples), "_samples_", min(samples$Year), "-", max(samples$Year))
?write_csv
write_csv(x = samples, file = paste0("./data/", nrow(samples), "_samples_", min(samples$Year), "-", max(samples$Year)))
write_csv(x = samples, file = paste0("./data/", nrow(samples), "_samples_", min(samples$Year), "-", max(samples$Year), ".csv"))
library(tidyverse, dplyr)
df <- read_csv("./data/195_samples_2009-2021.csv") %>% filter(who == "Morten")
gustav <- read_csv("./data/195_samples_2009-2021.csv") %>% filter(who == "Gustav")
morten <- read_csv("./data/195_samples_2009-2021.csv") %>% filter(who == "Morten")
View(morten)
doc_ids <- morten$doc_id %>% sort()
doc_ids
ids <- morten$id %>% sort()
ids
split = readline(prompt = paste0("is ", n, " split correctly?"))
docidddd <- 123
docidddd <- "123"
split <- "yes"
assignment <- "no"
assessment_results <- data.frame()
?rbind
row <- c(docidddd, split, assignment)
rbind(assessment_results, row)
View(assessment_results)
rbind(assessment_results, row)
assessment_results <- rbind(assessment_results, row)
View(assessment_results)
assessment_results <- data.frame("doc_id")
View(assessment_results)
setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
View(assessment_results)
assessment_results <- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
View(data)
View(assessment_results)
assessment_results <- rbind(assessment_results, row)
View(assessment_results)
?rbind
ratings[nrow(ratings)+1,] <- row
ratings <- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
row <- c(docidddd, split, assignment)
ratings[nrow(ratings)+1,] <- row
View(ratings)
morten <- read_csv("./data/195_samples_2009-2021.csv") %>% filter(who == "Morten") %>% slice(1:3)
doc_ids <- morten$doc_id %>% sort()
assessment <- function(doc_id){
ratings <<- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
split = readline(prompt = paste0("Is ", doc_id, " split correctly?"))
assignment = readline(prompt = paste0("Is ", doc_id, " split correctly?"))
row <- c(doc_id, split, assignment)
ratings[nrow(ratings)+i,] <- row
i = i + 1
}
assessment <- function(doc_id){
ratings <<- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
split = readline(prompt = paste0("Is ", doc_id, " split correctly?"))
assignment = readline(prompt = paste0("Is ", doc_id, " split correctly?"))
row <- c(doc_id, split, assignment)
ratings[nrow(ratings)+i,] <- row
i = i + 1
}
?map
map(.f = assessment, .x = doc_ids)
i = 1
assessment <- function(doc_id){
ratings <<- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
split = readline(prompt = paste0("Is the text in ", doc_id, " split correctly?"))
assignment = readline(prompt = paste0("Is the text in ", doc_id, " assigned correctly?"))
row <- c(doc_id, split, assignment)
ratings[nrow(ratings)+i,] <- row
i = i + 1
}
i = 1
map(.f = assessment, .x = doc_ids)
View(ratings)
assessment <- function(doc_id){
split = readline(prompt = paste0("Is the text in ", doc_id, " split correctly?"))
assignment = readline(prompt = paste0("Is the text in ", doc_id, " assigned correctly?"))
row <- c(doc_id, split, assignment)
ratings[nrow(ratings)+i,] <- row
i = i + 1
}
i = 1
ratings <<- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
map(.f = assessment, .x = doc_ids)
assessment <- function(doc_id){
split = readline(prompt = paste0("Is the text in ", doc_id, " split correctly?"))
assignment = readline(prompt = paste0("Is the text in ", doc_id, " assigned correctly?"))
row <- c(doc_id, split, assignment)
ratings[nrow(ratings)+i,] <<- row
i = i + 1
}
i = 1
ratings <<- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
map(.f = assessment, .x = doc_ids)
View(ratings)
assessment <- function(doc_id){
split = readline(prompt = paste0("Is the text in ", doc_id, " split correctly ?"))
assignment = readline(prompt = paste0("Is the text in ", doc_id, " assigned correctly? "))
row <- c(doc_id, split, assignment)
ratings[nrow(ratings)+i,] <<- row
i = i + 1
}
i = 1
ratings <<- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
map(.f = assessment, .x = doc_ids)
assessment <- function(doc_id){
split = readline(prompt = paste0("Is the text in ", doc_id, " split correctly? "))
assignment = readline(prompt = paste0("Is the text in ", doc_id, " assigned correctly? "))
row <- c(doc_id, split, assignment)
ratings[nrow(ratings)+i,] <<- row
i = i + 1
}
ratings <<- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
map(.f = assessment, .x = doc_ids)
View(results)
View(ratings)
hep <- map(.f = assessment, .x = doc_ids)
View(hep)
hep <- hep %>% unnest()
class(hep)
hep[1]
get_prior(f1, data = agg)
get_prior(f1, data = agg)
###################################################### MORTEN ######################################################
morten <- read_csv("./data/195_samples_2009-2021.csv") %>% filter(who == "Morten") %>% slice(1:3)
morten_ids <- morten$doc_id %>% sort()
assessment <- function(doc_id){
split = readline(prompt = paste0("Is the text in ", doc_id, " split correctly? "))
assignment = readline(prompt = paste0("Is the text in ", doc_id, " assigned correctly? "))
row <- c(doc_id, split, assignment)
ratings[nrow(ratings)+i,] <<- row
i = i + 1
}
i = 1
ratings <<- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c("doc_id", "split", "assignment"))
map(.f = assessment, .x = doc_ids)
# join by doc_id at the end
# i would like there to be an argument for df...
View(ratings)
View(morten)
library(tidyverse)
library(lubridate)
# library(udpipe)
library(stopwords)
library(groupdata2)
library(fuzzyjoin)
data3 <- read_csv("./data3_temp.csv")
############## ------------------ REMOVE WHEN DONE ------------------- ####################
##### CHECKING SIILAR NAMES #####
# Creating stringdist matrix for restaurant names
distmatrix<-stringdist::stringdistmatrix(unique(data3$Name),unique(data3$Name), useNames=TRUE ,method = "osa")
# Converting to dataframe
distmatrixdf<- as.data.frame(distmatrix)
# Making a row with restaurant names
distmatrixdf$Restaurant_Name <- rownames(distmatrixdf)
# Filtering out all links with less than 5 in distance and eyeballing the results to decide what links to merge
dist <- distmatrixdf %>%
pivot_longer(cols = everything(vars = distmatrixdf$Restaurant_Name)) %>%
filter(value != 0)
View(dist)
list_of_names <- data.frame(Name = unique(data3$Name))
View(list_of_names)
# Filtering out all links with less than 5 in distance and eyeballing the results to decide what links to merge
dist <- distmatrixdf %>%
pivot_longer(cols = everything(vars = distmatrixdf$Restaurant_Name)) %>%
filter(value <= 5 & value != 0)
View(dist)
?str_detect
############## ------------------ REMOVE WHEN DONE ------------------- ####################
##### CHECKING SIILAR NAMES #####
# Creating stringdist matrix for restaurant names
data3 <- data3 %>% filter(YEAR %in% seq(2000, 2021))
############## ------------------ REMOVE WHEN DONE ------------------- ####################
##### CHECKING SIILAR NAMES #####
# Creating stringdist matrix for restaurant names
data3 <- data3 %>% filter(Year %in% seq(2000, 2021))
distmatrix<-stringdist::stringdistmatrix(unique(data3$Name),unique(data3$Name), useNames=TRUE ,method = "osa")
# Converting to dataframe
distmatrixdf<- as.data.frame(distmatrix)
# Making a row with restaurant names
distmatrixdf$Restaurant_Name <- rownames(distmatrixdf)
# Filtering out all links with less than 5 in distance and eyeballing the results to decide what links to merge
dist <- distmatrixdf %>%
pivot_longer(cols = everything(vars = distmatrixdf$Restaurant_Name)) %>%
filter(value <= 5 & value != 0)
list_of_names <- data.frame(Name = unique(data3$Name))
View(dist)
View(dist)
View(list_of_names)
test <- data3 %>% group_by(Name) %>% count()
View(test)
# Creating stringdist matrix for restaurant names
data3 <- data3 %>% group_by(Name) %>% filter(n() >= 10) %>% ungroup()
data3 <- read_csv("./data3_temp.csv")
# Creating stringdist matrix for restaurant names
data3 <- data3 %>% group_by(Name) %>% filter(n() >= 10) %>% ungroup()
distmatrix <- stringdist::stringdistmatrix(unique(data3$Name),unique(data3$Name), useNames=TRUE ,method = "osa")
# Converting to dataframe
distmatrixdf<- as.data.frame(distmatrix)
# Making a row with restaurant names
distmatrixdf$Name <- rownames(distmatrixdf)
# Filtering out all links with less than 5 in distance and eyeballing the results to decide what links to merge
dist <- distmatrixdf %>%
pivot_longer(cols = everything(vars = distmatrixdf$Name)) %>%
filter(value <= 5 & value != 0)
hep <- hep %>% group_by(Name) %>% count()
hej <- left_join(dist, hep) %>% rename(n_left = n)
hh <- hep %>% rename(name = Name)
huj <- left_join(hej, hh) %>% rename(n_right = n)
View(huj)
hep <- data3 %>% group_by(Name) %>% count()
hej <- left_join(dist, hep) %>% rename(n_left = n)
hh <- hep %>% rename(name = Name)
huj <- left_join(hej, hh) %>% rename(n_right = n)
View(huj)
list_of_names <- data.frame(Name = unique(data3$Name))
View(list_of_names)
View(hep)
# Importing data
#csv_files = list.files(pattern="*.csv", path = "data/wordshoal_results/", full.names = T)
#df = map_df(csv_files, read_csv)
ws_df <- read_csv("./data/wordshoal_results/wordshoal_estimates_2019_2019.csv")
# loading packages
pacman::p_load(tidyverse,stringdist, ggplot2, lubridate)
# Color pallette
pal <- wesanderson::wes_palette("Darjeeling1", 16, type = "continuous")
# Importing data
#csv_files = list.files(pattern="*.csv", path = "data/wordshoal_results/", full.names = T)
#df = map_df(csv_files, read_csv)
ws_df <- read_csv("./data/wordshoal_results/wordshoal_estimates_2019_2019.csv")
# Importing data
#csv_files = list.files(pattern="*.csv", path = "data/wordshoal_results/", full.names = T)
#df = map_df(csv_files, read_csv)
ws_df <- read_csv("./data/wordshoal_results/wordshoal_estimates_2019_2019.csv")
# Importing data
#csv_files = list.files(pattern="*.csv", path = "data/wordshoal_results/", full.names = T)
#df = map_df(csv_files, read_csv)
ws_df <- read_csv("./data/wordshoal_results/wordshoal_estimates_2018_2021.csv")
raw_df <- read_csv("./data/folketinget_2009_2021_raw.csv")
# Mean position and sd of position per month and party
agg <- ws_df %>% group_by(Parti, Month) %>% summarise(mean = mean(theta), sd = sd(theta)) %>% drop_na(sd)
View(ws_df)
# Mean position and sd of position per month and party
#agg <- ws_df %>% group_by(Parti, Month) %>% summarise(mean = mean(theta), sd = sd(theta)) %>% drop_na(sd)
agg <- ws_df %>% group_by(Parti, month_year_id) %>% summarise(mean = mean(theta), sd = sd(theta)) %>% drop_na(sd)
# Mean position of each member grouped by party
ws_df %>% group_by(row_names) %>% summarise(Parti = Parti, mean_theta = mean(theta)) %>% filter(!duplicated(mean_theta)) %>% filter(!row_names %in% c("Thor Pedersen", "Anders Fogh Rasmussen", "SÃ¸ren Gade")) %>%
ggplot()+
aes(x = mean_theta, y = Parti, color = Parti)+
geom_point()+
scale_color_manual(values = wesanderson::wes_palette("Darjeeling1", 10, type = "continuous"))+
labs(title = "Wordshoal - Mean estimated position of each member divided by party", x = "Estimated position", y ="")+
theme(legend.position = "none")
# loading packages
pacman::p_load(tidyverse,stringdist, overlapping, lubridate)
# Importing data
df <- read_csv("data/folketinget_2009_2021_raw.csv") %>% filter(Year %in% c(2019, 2020))
# Color pallette
pal <- wesanderson::wes_palette("Darjeeling1", 14, type = "continuous")
# Setting up the theme
theme_set(theme_minimal())
# Loading the results
#csv_files = list.files(pattern="*.csv", path = "data/wordshoal_results/", full.names = T)
#df = map_df(csv_files, read_csv)
df_ws <- read_csv("./data/wordshoal_results/wordshoal_estimates_2018_2021.csv")
# FUNCTION
overlapper <- function(period){
# Printing status
print(paste0("[ ] Calculating overlaps for month: ", period, ". Number: ", i, " out of ", as.character(length(unique(df$Month)))))
# Subsetting the period and filtering out parties that only has 1 speech in a month
subset <- df %>% filter(Month == period) %>% group_by(Parti) %>% filter(n() > 1) %>% ungroup()
# Only continue if there is more than one party with more than one speech
if(length(unique(subset$Parti)) > 1){
# Making a list of parties
parties <- unique(subset$Parti)
# Converting into wide format
wide <- subset %>% pivot_wider(names_from = Parti, values_from = theta)
# Creating an empty list
list <- list()
# Adding the parties to the list
for(party in parties){
list <- append(list,na.omit(select(wide, party)))
}
# Calculating the overlaps
overlaps <- overlap(list)
# Wringling the data
results <- data.frame(overlaps$OV) %>% rownames_to_column("Parties") %>%
separate(Parties, c("From","To"), "-")
# Making an empty data frame to append to
end_results = data_frame()
# Wrangling the result data frame
for(party in parties){
hep <- results %>% filter(From == party | To == party) %>% mutate(
copy_from = From,
From = ifelse(From == party, From, To),
To = ifelse(To == party, copy_from, To)
) %>% select(-copy_from)
end_results <- rbind(end_results, hep)
}
# Adding month_year_id variable
end_results$Month <- period
i <<- i + 1
return(end_results)
}
}
View(df_ws)
