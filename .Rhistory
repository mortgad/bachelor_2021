}
d = d %>%
filter(complete.cases(text), complete.cases(Name)) %>%
mutate(id = tools::file_path_sans_ext(basename(filename))) %>%
as_data_frame()
return(d)
}
files = list.files("./data/segmented", "*.txt", full.names = TRUE)
data = map_dfr(files, tidy_text) %>%
## bind_rows() %>%
right_join(meta, by = "id") %>%
mutate(Date = parse_date_time(str_c(Dato, Time, sep = " "),
orders = c("dmy HMS", "dmy MS", "dmy S"))) %>%
filter(complete.cases(Date)) %>%
arrange(Date) %>%
mutate(speaker_id = ifelse(lag(Name) != Name, 1, 0) %>%
coalesce(0) %>%
cumsum()) %>%
group_by(Name, id, Samling, Nr, Titel, Dato, speaker_id) %>%
summarise(text = str_c(text, collapse = " "),
Date = min(Date)) %>% ungroup() %>%
mutate(doc_id = as.character(as.integer(as.factor(str_c(speaker_id, Name, Date))))) %>%
ungroup()
View(data)
test_file = read_delim("./data/segmented/20191_M1_referat.txt", delim = ";")
View(test_file)
# loading packages
pacman::p_load(tidyverse,stringdist)
#################### INSPECTING THE RESULTS ###########################
# Import the results
results <- read_csv("../data/cv_results.csv")
View(results)
head(results)
results %>%
group_by(Year) %>%
summarise(mean(kappa_test))
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggpplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line()
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggpplot()+
aes(x = Year, y = kappa)+
geom_point()+
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggpplot()+
aes(x = Year, y = kappa)+
geom_point()
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line()
# Color pallette
pal <- wesanderson::wes_palette("Darjeeling1", 14, type = "continuous")
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[1])
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])
# Setting up the theme
theme_set(theme_minimal())
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])+
labs(y = "Kappa score", title = "Level of polarization in Folketinget")
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])+
ylim(0, 1)+
labs(y = "Kappa score", title = "Level of polarization in Folketinget")
#################### INSPECTING THE RESULTS ###########################
# Import the results
results <- read_csv("../data/cv_results_2009.csv")
# loading packages
pacman::p_load(tidyverse,stringdist)
#################### INSPECTING THE RESULTS ###########################
# Import the results
results <- read_csv("../data/cv_results_2009.csv")
#################### INSPECTING THE RESULTS ###########################
# Import the results
results <- read_csv("../data/cv_results_subset.csv")
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])+
ylim(0, 1)+
labs(y = "Kappa score", title = "Level of polarization in Folketinget")
View(results)
hist(results$alpha)
count(results$alpha)
count(as.factor(results$alpha))
results %>% group_by(alpha) %>% n()
results %>% group_by(alpha) %>% count()
load("~/Documents/Cognitive Science/5_semester/Bachelor/Bachelor_2021/Goet_Scripts/wordshoal_implementations/1.full_scaling/wfms/wfm_dat_4.5.RData")
load("~/Documents/Cognitive Science/5_semester/Bachelor/Bachelor_2021/Goet_Scripts/wordshoal_implementations/1.full_scaling/wfms/wfm_dat_4.5.RData")
View(metadat)
View(wcdata)
load("~/Documents/Cognitive Science/5_semester/Bachelor/Bachelor_2021/Goet_Scripts/wordshoal_implementations/3.wordshoal/wfms_debate_level 2/wfm_dat_4.5_1.RData")
View(metadat)
View(wcdata)
View(metadat)
View(metadat)
# loading packages
pacman::p_load(tidyverse,stringdist)
# Importing data
df <- read_csv("/Users/gustavhelms/Documents/Cognitive Science/5_semester/Bachelor/political_polarization/Folketinget-Scraping/data/folketinget_2019_2021_raw.csv")
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% summarise(text = paste(text))
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% summarise(text = paste(text))
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% summarise(text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% mutate(aggr_text = paste(text, collapse = " "))
View(hep)
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% summarise(aggr_text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(Name, id) %>% summarise(aggr_text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(id) %>%  ggroup_by(Name) %>% summarise(aggr_text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(id) %>%  group_by(Name) %>% summarise(aggr_text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(id) %>% summarise(aggr_text = paste(text, collapse = " "))
View(hep)
View(metadat)
View(metadat)
# Importing data
df <- read_csv("/Users/gustavhelms/Documents/Cognitive Science/5_semester/Bachelor/political_polarization/Folketinget-Scraping/data/folketinget_2019_2021_raw.csv")
# loading packages
pacman::p_load(tidyverse, corpus)
# loading packages
pacman::p_load(tidyverse, corpus)
# Loading the packages
library(quanteda)
library(wordshoal)
library(quanteda.textmodels)
# Importing data
df <- read_csv("/Users/gustavhelms/Documents/Cognitive Science/5_semester/Bachelor/political_polarization/Folketinget-Scraping/data/folketinget_2019_2021_raw.csv")
# Subsetting to only five documents
subset <- df %>% filter(id == c("20201_M108_referat", "20201_M114_referat",
"20201_M110_referat", "20201_M117_referat", "20201_M126_referat"))
# Making the df into a corpus
corpus <- corpus(subset)
# Create a data frame matrix (dfm)
dfm <- dfm(tokens(corpus), remove_punct = TRUE)
# Fitting the model
wordshoalfit <-
textmodel_wordshoal(dfm, #dir = c(7,1), # I cannot figure out what the 'dir' argument does
groups = docvars(corpus, "id"),
authors = docvars(corpus, "Name"))
# Inspecting the output
summary(wordshoalfit)
# loading packages
pacman::p_load(tidyverse, corpus, devtools, lubridate, flux)
# Installing the latest version of quanteda and wordshoal
#devtools::install_github("https://github.com/quanteda/quanteda")
#remotes::install_github("kbenoit/wordshoal")
# Loading the packages
library(quanteda)
library(wordshoal)
library(quanteda.textmodels)
# Importing data
df <- read_csv("./data/folketinget_2009_2021_raw.csv")
# Making a month and year unique variable
df <- df %>% mutate(
month_year_id = paste0(Year,"_", month(Date))
) %>% select(-c(Title))
# Checking party labels
df %>% group_by(Parti) %>% count()
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
df <- df %>% filter(Parti != parties_to_remove)
# Filtering out parties
parties_to_remove <- c("Uden for Partierne", "Venstresocialisterne")
df <- df %>% filter(Parti != parties_to_remove)
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
df <- df %>% filter(Parti != parties_to_remove)
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
df <- df %>% filter(Parti != parties_to_remove)
df <- df %>% filter(!Parti %in% parties_to_remove)
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>% filter(!Parti %in% parties_to_remove)
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
# Changing konservative folkeparti
df <- df %>% mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti)
)
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
# Changing konservative folkeparti
df <- df %>% mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti)
) %>%
#removing documents with less than 10 speaches
group_by(id) %>% count() %>% arrange()
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
View(df)
# Changing konservative folkeparti
df <- df %>% mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti)
) %>%
#removing documents with less than 10 speaches
group_by(id) %>% count() %>% arrange(n)
# Changing konservative folkeparti
df <- df %>% mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti)
) %>%
#removing documents with less than 10 speaches
group_by(id) %>% count() %>% arrange(n)
# Importing data
df <- read_csv("./data/folketinget_2009_2021_raw.csv")
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti)
) %>%
group_by(id) %>%
filter(n() > 10)
#removing documents with less than 10 speaches
df %>% group_by(id) %>% count() %>% arrange(n)
# Importing data
df <- read_csv("./data/folketinget_2009_2021_raw.csv")
# Importing data
df <- read_csv("./data/folketinget_2009_2021_raw.csv")
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) #%>%
#removing documents with less than 10 speaches
df %>% group_by(id) %>% count() %>% arrange(n)
#removing documents with less than 10 speaches
df %>% group_by(id) %>% filter(n() < 10) %>% count() %>% arrange(n)
#removing documents with less than 10 speaches
df %>% group_by(id) %>% filter(n() < 10) %>% ungroup() %>% count()
#removing documents with less than 10 speaches
df %>% group_by(id) %>% filter(n() > 10) %>% ungroup() %>% count()
#removing documents with less than 10 speaches
df %>% group_by(id) %>% filter(n() < 10) %>% ungroup() %>% count()
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup(10) %>%
select(-c(Title))
years = range(2015:2021)
years = range(2015,2021)
years = seq(2015,2021)
years
filename = paste0("wordshoal_estimates_", min(years), "_", max(years))
filename = paste0("wordshoal_estimates_", min(years), "_", max(years), ".csv")
years = seq(2015,2021)
df_subset <- df %>% filter(Year %in% years)
years = seq(2016,2021)
df_subset <- df %>% filter(Year %in% years)
filename = paste0("./data/wordshoal_estimates_", min(years), "_", max(years), ".csv")
write_csv(df_subset, filename)
filename = paste0("./data/wordshoal_results/wordshoal_estimates_", min(years), "_", max(years), ".csv")
write_csv(df_subset, filename)
df_subset <- df %>% filter(Year %in% years) %>% group_by(id) %>% slice(0:100) %>% ungroup()
years = seq(2021)
years = seq(2021,2021)
df_subset <- df %>% filter(Year %in% years) %>% group_by(id) %>% slice(0:100) %>% ungroup()
years = seq(2020,2020)
df_subset <- df %>% filter(Year %in% years) %>% group_by(id) %>% slice(0:100) %>% ungroup()
############## corpus per month ###################
#dfny %>% group_by(id) %>% summarise(n()) # to see number of rows per pdf
years = seq(2020,2020)
df_subset <- df %>% filter(Year %in% years) %>% group_by(id) %>% slice(0:100) %>% ungroup()
months = unique(df_subset$month_year_id)  # input list
#months %>% sort()
#hep <- years_2019_2020 %>% filter(month_year_id == "2019_11") # see if wordshoal finds amount of documents per month
#unique(hep$id)
wordshoaler <- function(doc) {
cat(paste0("[ ] Shoaling ", doc, "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(doc))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
}
thetascores <- data.frame()
map(months, wordshoaler)
# loading packages
pacman::p_load(tidyverse, corpus, devtools, lubridate, flux)
# Installing the latest version of quanteda and wordshoal
#devtools::install_github("https://github.com/quanteda/quanteda")
#remotes::install_github("kbenoit/wordshoal")
# Loading the packages
library(quanteda)
library(wordshoal)
library(quanteda.textmodels)
# Importing data
df <- read_csv("./data/folketinget_2009_2021_raw.csv")
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup(10) %>%
select(-c(Title))
############## corpus per month ###################
years = seq(2010,2015) # Years to loop through
df_subset <- df %>% filter(Year %in% years)
months = unique(df_subset$month_year_id) # input list
i=1
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", month, " Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
map(months, wordshoaler)
View(df_subset)
?dfm
df_2011_11 <- df %>% filter(month_year_id == "2011_11")
wordshoaler(df_2011_11)
corpus11 <- quanteda::corpus(df_2011_11)
dfm11 <-dfm(tokens(corpuseret), remove_punct = TRUE)
dfm11 <-dfm(tokens(corpus11), remove_punct = TRUE)
corpus11 <- quanteda::corpus(df_2011_11)
View(df_2011_11)
View(df_2011_11)
df_2011_10 <- df %>% filter(month_year_id == "2011_10")
corpus10 <- quanteda::corpus(df_2011_10)
corpus10[2]
docvars(corpus10)
docnames(corpus10)
df_2011_11 %>% group_by(doc_id) %>% count() %>% arrange(-n)
# loading packages
pacman::p_load(tidyverse, corpus, devtools, lubridate, flux)
# Installing the latest version of quanteda and wordshoal
#devtools::install_github("https://github.com/quanteda/quanteda")
#remotes::install_github("kbenoit/wordshoal")
# Loading the packages
library(quanteda)
library(wordshoal)
library(quanteda.textmodels)
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup() %>%
# Removing all formand because of procedural and lots of mistakes.
filter(!Title %in% c("Formanden","Formand")) %>%
# filtering out all duplicates
group_by(doc_id) %>% filter(n() < 2) %>% ungroup()
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup() %>%
# Removing all formand because of procedural and lots of mistakes.
filter(!Title %in% c("Formanden","Formand")) %>%
# filtering out all duplicates
group_by(doc_id) %>% filter(n() < 2) %>% ungroup()
# Importing data
df <- read_csv("./data/folketinget_2009_2021_raw.csv")
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup() %>%
# Removing all formand because of procedural and lots of mistakes.
filter(!Title %in% c("Formanden","Formand")) %>%
# filtering out all duplicates
group_by(doc_id) %>% filter(n() < 2) %>% ungroup()
############## corpus per month ###################
years = seq(2010,2010) # Years to loop through
df_subset <- df %>% filter(Year %in% years)
months = unique(df_subset$month_year_id) # input list
i=1
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", month, ". Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
map(months, wordshoaler)
# writing the estimates
filename = paste0("./data/wordshoal_results/wordshoal_estimates_", min(years), "_", max(years), ".csv")
write_csv(thetascores, filename)
View(thetascores)
write_csv(thetascores, "data/wordshoal_estimates_2010_2010.csv")
