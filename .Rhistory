hep = read_csv("./data/folketinget_2019_2021_raw.csv")
library(tidyverse)
hep = read_csv("./data/folketinget_2019_2021_raw.csv")
View(hep)
library(tidyverse)
library(lubridate)
library(groupdata2)
library(fuzzyjoin)
# library(udpipe)
library(stopwords)
title_re_paren = "(?<=\\().*(?=\\))"
title_re_noparen = ".*"
name_re = "[\\w\\s-\\.]+"
# load in metadata
meta = read_delim("./data/metadata_for_scraping/metadata.csv", ";", col_types = cols()) %>%
mutate(id = tools::file_path_sans_ext(basename(PDF))) %>%
select(-PDF, -X6)
View(meta)
tidy_text <- function(filename) {
cat(paste0("[ ] Tidying ", filename, "\n"))
d = read_delim(filename, delim = ";", col_types = cols()) %>%
filter(complete.cases(reason))
if (nrow(d) < 3) return(data.frame(NA))
if (!any(str_detect(d$reason, "name"))) return (data.frame(NA))
d = d %>%
filter(split > 0) %>%
mutate(value = case_when(
reason == "title_name" ~ ifelse(
str_detect(value, "\\(|\\)"),
str_extract(value, title_re_paren),
str_extract(value, title_re_noparen)),
reason == "name_party" ~ str_extract(value, name_re),
reason == "Time" ~ value),
reason = ifelse(reason == "Time", "Time", "Name"),
value = trimws(value)) %>%
spread(reason, value) %>%
select(-split)
if ("Time" %in% colnames(d)) {
d = d %>%
fill(Time, Name) %>%
mutate(Time = hm(Time))
} else {
d$Time = hm(NA)
}
d = d %>%
filter(complete.cases(text), complete.cases(Name)) %>%
mutate(id = tools::file_path_sans_ext(basename(filename))) %>%
as_data_frame()
return(d)
}
files = list.files("./data/segmented", "*.txt", full.names = TRUE)
data = map_dfr(files, tidy_text) %>%
## bind_rows() %>%
right_join(meta, by = "id") %>%
mutate(Date = parse_date_time(str_c(Dato, Time, sep = " "),
orders = c("dmy HMS", "dmy MS", "dmy S"))) %>%
filter(complete.cases(Date)) %>%
arrange(Date) %>%
mutate(speaker_id = ifelse(lag(Name) != Name, 1, 0) %>%
coalesce(0) %>%
cumsum()) %>%
group_by(Name, id, Samling, Nr, Titel, Dato, speaker_id) %>%
summarise(text = str_c(text, collapse = " "),
Date = min(Date)) %>% ungroup() %>%
mutate(doc_id = as.character(as.integer(as.factor(str_c(speaker_id, Name, Date))))) %>%
ungroup()
View(data)
test_file = read_delim("./data/segmented/20191_M1_referat.txt", delim = ";")
View(test_file)
# loading packages
pacman::p_load(tidyverse,stringdist)
#################### INSPECTING THE RESULTS ###########################
# Import the results
results <- read_csv("../data/cv_results.csv")
View(results)
head(results)
results %>%
group_by(Year) %>%
summarise(mean(kappa_test))
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggpplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line()
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggpplot()+
aes(x = Year, y = kappa)+
geom_point()+
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggpplot()+
aes(x = Year, y = kappa)+
geom_point()
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line()
# Color pallette
pal <- wesanderson::wes_palette("Darjeeling1", 14, type = "continuous")
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[1])
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])
# Setting up the theme
theme_set(theme_minimal())
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])+
labs(y = "Kappa score", title = "Level of polarization in Folketinget")
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])+
ylim(0, 1)+
labs(y = "Kappa score", title = "Level of polarization in Folketinget")
#################### INSPECTING THE RESULTS ###########################
# Import the results
results <- read_csv("../data/cv_results_2009.csv")
# loading packages
pacman::p_load(tidyverse,stringdist)
#################### INSPECTING THE RESULTS ###########################
# Import the results
results <- read_csv("../data/cv_results_2009.csv")
#################### INSPECTING THE RESULTS ###########################
# Import the results
results <- read_csv("../data/cv_results_subset.csv")
results %>%
group_by(Year) %>%
summarise(kappa = mean(kappa_test)) %>%
ggplot()+
aes(x = Year, y = kappa)+
geom_point()+
geom_line(color = wesanderson::wes_palette("Darjeeling1")[2])+
ylim(0, 1)+
labs(y = "Kappa score", title = "Level of polarization in Folketinget")
View(results)
hist(results$alpha)
count(results$alpha)
count(as.factor(results$alpha))
results %>% group_by(alpha) %>% n()
results %>% group_by(alpha) %>% count()
load("~/Documents/Cognitive Science/5_semester/Bachelor/Bachelor_2021/Goet_Scripts/wordshoal_implementations/1.full_scaling/wfms/wfm_dat_4.5.RData")
load("~/Documents/Cognitive Science/5_semester/Bachelor/Bachelor_2021/Goet_Scripts/wordshoal_implementations/1.full_scaling/wfms/wfm_dat_4.5.RData")
View(metadat)
View(wcdata)
load("~/Documents/Cognitive Science/5_semester/Bachelor/Bachelor_2021/Goet_Scripts/wordshoal_implementations/3.wordshoal/wfms_debate_level 2/wfm_dat_4.5_1.RData")
View(metadat)
View(wcdata)
View(metadat)
View(metadat)
# loading packages
pacman::p_load(tidyverse,stringdist)
# Importing data
df <- read_csv("/Users/gustavhelms/Documents/Cognitive Science/5_semester/Bachelor/political_polarization/Folketinget-Scraping/data/folketinget_2019_2021_raw.csv")
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% summarise(text = paste(text))
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% summarise(text = paste(text))
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% summarise(text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% mutate(aggr_text = paste(text, collapse = " "))
View(hep)
# Aggregating speeches
hep <- df %>% group_by(id, Name) %>% summarise(aggr_text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(Name, id) %>% summarise(aggr_text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(id) %>%  ggroup_by(Name) %>% summarise(aggr_text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(id) %>%  group_by(Name) %>% summarise(aggr_text = paste(text, collapse = " "))
# Aggregating speeches
hep <- df %>% group_by(id) %>% summarise(aggr_text = paste(text, collapse = " "))
View(hep)
View(metadat)
View(metadat)
# Importing data
df <- read_csv("/Users/gustavhelms/Documents/Cognitive Science/5_semester/Bachelor/political_polarization/Folketinget-Scraping/data/folketinget_2019_2021_raw.csv")
# loading packages
pacman::p_load(tidyverse, corpus)
# loading packages
pacman::p_load(tidyverse, corpus)
# Loading the packages
library(quanteda)
library(wordshoal)
library(quanteda.textmodels)
# Importing data
df <- read_csv("/Users/gustavhelms/Documents/Cognitive Science/5_semester/Bachelor/political_polarization/Folketinget-Scraping/data/folketinget_2019_2021_raw.csv")
# Subsetting to only five documents
subset <- df %>% filter(id == c("20201_M108_referat", "20201_M114_referat",
"20201_M110_referat", "20201_M117_referat", "20201_M126_referat"))
# Making the df into a corpus
corpus <- corpus(subset)
# Create a data frame matrix (dfm)
dfm <- dfm(tokens(corpus), remove_punct = TRUE)
# Fitting the model
wordshoalfit <-
textmodel_wordshoal(dfm, #dir = c(7,1), # I cannot figure out what the 'dir' argument does
groups = docvars(corpus, "id"),
authors = docvars(corpus, "Name"))
# Inspecting the output
summary(wordshoalfit)
