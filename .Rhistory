backend = "cmdstanr"#,
#file = here("models", "m1")
)
# Posterior predictive check
pp_check(m1, nsamples = 100)
# Diagnostics
# Summary output
print(m1)
#Checking the chains
plot(m1)
#---------------------------------prior-posterior update------------------------
#Prior posterior update checks
m1_samples <- posterior_samples(m1)
m1_samples %>%
select(c("b_Lag_inclusion", "b_Lag_differentiation", "b_Lag_inclusion:Lag_differentiation", "sd_Parti__Intercept", "sigma", "Intercept",
"prior_Intercept", "prior_b", "prior_sd_Parti", "prior_sigma")) %>%
rename(
b_lagInclusion = b_Lag_inclusion,
b_lagDifferentiation = b_Lag_differentiation,
b_Interaction = "b_Lag_inclusion:Lag_differentiation",
b_sdParti = sd_Parti__Intercept,
b_sigma = sigma,
b_Intercept = Intercept,
prior_Intercept = prior_Intercept,
prior_sdParti = prior_sd_Parti,
) %>%
mutate(
prior_lagInclusion = prior_b,
prior_lagDifferentiation = prior_b,
prior_Interaction = prior_b
) %>% select(-prior_b) %>%
pivot_longer(cols = everything(),
values_to = "value",
names_to = "distribution"
) %>%
separate(distribution, c("Distribution", "Parameter"), sep = "_") %>%
mutate(Distribution = ifelse(Distribution == "b", "Posterior", "Prior")) %>%
ggplot(aes(x = value, fill = Distribution)) +
geom_density(alpha = 0.8) +
facet_wrap(~Parameter, nrow = 4) +
labs(title = "Prior-posterior updates")+
theme_bw()+
scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +
theme(strip.text = element_text(size=15),
axis.title=element_text(size=15),
plot.title = element_text(size = 15, face = "bold", hjust = 0.5)) +
xlim(-1,1)
#---------------------------------prior-posterior update - a little closer look ------------------------
#Prior posterior update checks
m1_samples <- posterior_samples(m1)
m1_samples %>%
select(c("b_Lag_inclusion", "b_Lag_differentiation", "b_Lag_inclusion:Lag_differentiation",
"prior_b")) %>%
rename(
b_lagInclusion = b_Lag_inclusion,
b_lagDifferentiation = b_Lag_differentiation,
b_Interaction = "b_Lag_inclusion:Lag_differentiation"
) %>%
mutate(
prior_lagInclusion = prior_b,
prior_lagDifferentiation = prior_b,
prior_Interaction = prior_b
) %>% select(-prior_b) %>%
pivot_longer(cols = everything(),
values_to = "value",
names_to = "distribution"
) %>%
separate(distribution, c("Distribution", "Parameter"), sep = "_") %>%
mutate(Distribution = ifelse(Distribution == "b", "Posterior", "Prior")) %>%
ggplot(aes(x = value, fill = Distribution)) +
geom_density(alpha = 0.8) +
facet_wrap(~Parameter, nrow = 1) +
labs(title = "Prior-posterior updates")+
theme_bw()+
scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +
theme(strip.text = element_text(size=15),
axis.title=element_text(size=15),
plot.title = element_text(size = 15, face = "bold", hjust = 0.5)) +
xlim(-1,1)
#-----------------------------------Results-------------------------------------
#checking the output of the model
print(m1)
mcmc_plot(m1) +
theme(axis.text.y = element_text(hjust = 0))
#test your hypotheses
# Significant effect of Diagnosis in DK?
hypothesis(m1, "Lag_inclusion < 0")
plot(hypothesis(m1, "Lag_inclusion < 0"))
# Significant effect of Diagnosis in US?
hypothesis(m1, "Lag_differentiation < 0")
plot(hypothesis(m1, "Lag_differentiation < 0"))
# Significant difference between DK and US?
hypothesis(m1, "Lag_inclusion:Lag_differentiation < 0")
plot(hypothesis(m1, "Lag_inclusion:Lag_differentiation < 0"))
prior_m1 <- c(
prior(normal(0.4, 0.2), class = Intercept),
prior(normal(0, 0.2), class = b),
prior(normal(0.4486, 0.2428), class = sd),
prior(exponential(5), class = sigma)
)
# Running the model
m1_prior <- brm(
formula = f1,
data = na.omit(agg),
family = gaussian(),
prior = prior_m1,
sample_prior = "only",
chains = 1,
cores = 1,
backend = "cmdstanr"
#file = here("models", "m1_prior")
)
f1 <- bf(Inclusion ~ 1 + Lag_inclusion + Lag_differentiation + Lag_inclusion:Lag_differentiation + (1|Parti))
prior_m1 <- c(
prior(normal(0.4, 0.2), class = Intercept),
prior(normal(0, 0.2), class = b),
prior(normal(0.4486, 0.2428), class = sd),
prior(exponential(5), class = sigma)
)
# Running the model
m1_prior <- brm(
formula = f1,
data = na.omit(agg),
family = gaussian(),
prior = prior_m1,
sample_prior = "only",
chains = 1,
cores = 1,
backend = "cmdstanr"
#file = here("models", "m1_prior")
)
# Prior predictive check
pp_check(m1_prior, nsamples = 100)
############################ RUNNING THE MODEL WITH DATA  #####################################
# Running the model
m1 <- brm(
formula = f1,
data = na.omit(agg) %>% mutate(Inclusion =  ifelse(Inclusion == 0, 0.001, Inclusion)),
family = brmsfamily("lognormal", link_sigma = "identity"),
prior = prior_m1,
sample_prior = T,
chains = 1,
cores = 1,
backend = "cmdstanr"#,
#file = here("models", "m1")
)
# Posterior predictive check
pp_check(m1, nsamples = 100)
############################ RUNNING THE MODEL WITH DATA  #####################################
# Running the model
m1 <- brm(
formula = f1,
data = na.omit(agg),
family = gaussian(),
prior = prior_m1,
sample_prior = T,
chains = 1,
cores = 1,
backend = "cmdstanr"#,
#file = here("models", "m1")
)
############################ RUNNING THE MODEL WITH DATA  #####################################
# Running the model
m1 <- brm(
formula = f1,
data = na.omit(agg),
family = gaussian(),
prior = prior_m1,
sample_prior = T,
chains = 1,
cores = 1,
backend = "cmdstanr"#,
#file = here("models", "m1")
)
# Posterior predictive check
pp_check(m1, nsamples = 100)
#---------------------------------prior-posterior update------------------------
#Prior posterior update checks
m1_samples <- posterior_samples(m1)
m1_samples %>%
select(c("b_Lag_inclusion", "b_Lag_differentiation", "b_Lag_inclusion:Lag_differentiation", "sd_Parti__Intercept", "sigma", "Intercept",
"prior_Intercept", "prior_b", "prior_sd_Parti", "prior_sigma")) %>%
rename(
b_lagInclusion = b_Lag_inclusion,
b_lagDifferentiation = b_Lag_differentiation,
b_Interaction = "b_Lag_inclusion:Lag_differentiation",
b_sdParti = sd_Parti__Intercept,
b_sigma = sigma,
b_Intercept = Intercept,
prior_Intercept = prior_Intercept,
prior_sdParti = prior_sd_Parti,
) %>%
mutate(
prior_lagInclusion = prior_b,
prior_lagDifferentiation = prior_b,
prior_Interaction = prior_b
) %>% select(-prior_b) %>%
pivot_longer(cols = everything(),
values_to = "value",
names_to = "distribution"
) %>%
separate(distribution, c("Distribution", "Parameter"), sep = "_") %>%
mutate(Distribution = ifelse(Distribution == "b", "Posterior", "Prior")) %>%
ggplot(aes(x = value, fill = Distribution)) +
geom_density(alpha = 0.8) +
facet_wrap(~Parameter, nrow = 4) +
labs(title = "Prior-posterior updates")+
theme_bw()+
scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +
theme(strip.text = element_text(size=15),
axis.title=element_text(size=15),
plot.title = element_text(size = 15, face = "bold", hjust = 0.5)) +
xlim(-1,1)
#---------------------------------prior-posterior update - a little closer look ------------------------
#Prior posterior update checks
m1_samples <- posterior_samples(m1)
m1_samples %>%
select(c("b_Lag_inclusion", "b_Lag_differentiation", "b_Lag_inclusion:Lag_differentiation",
"prior_b")) %>%
rename(
b_lagInclusion = b_Lag_inclusion,
b_lagDifferentiation = b_Lag_differentiation,
b_Interaction = "b_Lag_inclusion:Lag_differentiation"
) %>%
mutate(
prior_lagInclusion = prior_b,
prior_lagDifferentiation = prior_b,
prior_Interaction = prior_b
) %>% select(-prior_b) %>%
pivot_longer(cols = everything(),
values_to = "value",
names_to = "distribution"
) %>%
separate(distribution, c("Distribution", "Parameter"), sep = "_") %>%
mutate(Distribution = ifelse(Distribution == "b", "Posterior", "Prior")) %>%
ggplot(aes(x = value, fill = Distribution)) +
geom_density(alpha = 0.8) +
facet_wrap(~Parameter, nrow = 1) +
labs(title = "Prior-posterior updates")+
theme_bw()+
scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +
theme(strip.text = element_text(size=15),
axis.title=element_text(size=15),
plot.title = element_text(size = 15, face = "bold", hjust = 0.5)) +
xlim(-1,1)
# loading packages
pacman::p_load(tidyverse, corpus, devtools, lubridate, flux, stopwords, seededlda, maps)
# Installing the latest version of quanteda and wordshoal
#devtools::install_github("https://github.com/quanteda/quanteda")
#remotes::install_github("kbenoit/wordshoal")
#devtools::install_github("quanteda/quanteda.corpora")
# Loading the packages
library(quanteda)
library(wordshoal)
library(quanteda.textmodels)
library(quanteda.corpora)
# Importing data
df <- read_csv("./data/folketinget_2009_2021_raw.csv")
summary(df$Date)
# Checking party labels
df %>% group_by(Parti) %>% count() %>% arrange(-n)
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
Parti = ifelse(Parti == "Det Radikale Venstre","Radikale Venstre", Parti),
month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup() %>%
# Removing all formand because of procedural and lots of mistakes.
filter(!Title %in% c("Formanden","Formand")) %>%
# filtering out all duplicates
group_by(doc_id) %>% filter(n() < 2) %>% ungroup()
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
Parti = ifelse(Parti == "Det Radikale Venstre","Radikale Venstre", Parti),
month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup() %>%
# Removing all formand because of procedural and lots of mistakes.
filter(!Title %in% c("Formanden","Formand")) %>%
# filtering out all duplicates
group_by(doc_id) %>% filter(n() < 2) %>% ungroup()
summary(df$Date)
############## corpus per month ###################
years = seq(2009,2021) # Years to loop through
df_subset <- df %>% filter(Year %in% years)
months = unique(df_subset$month_year_id) # input list
i=1
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", month, ". Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE, ignoredFeatures = stopwords("danish")) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
map(months, wordshoaler)
months
map(months, wordshoaler)
map(months, wordshoaler)
map(months, wordshoaler)
months
class(months)
map(as.character(months), wordshoaler)
# Filtering out parties
parties_to_remove <- c("Uden for partierne", "Venstresocialisterne")
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
Parti = ifelse(Parti == "Det Radikale Venstre","Radikale Venstre", Parti)#,
#month_year_id = paste0(Year,"_", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup() %>%
# Removing all formand because of procedural and lots of mistakes.
filter(!Title %in% c("Formanden","Formand")) %>%
# filtering out all duplicates
group_by(doc_id) %>% filter(n() < 2) %>% ungroup()
############## corpus per month ###################
years = seq(2009,2021) # Years to loop through
df_subset <- df %>% filter(Year %in% years)
months = unique(df_subset$month_year_id) # input list
i=1
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", month, ". Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE, ignoredFeatures = stopwords("danish")) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
map(months, wordshoaler)
############## corpus per month ###################
years = seq(2009,2021) # Years to loop through
df_subset <- df %>% filter(Year %in% years)
months = unique(df_subset$month_year_id) # input list
i=1
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", paste0(month), ". Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE, ignoredFeatures = stopwords("danish")) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
map(months, wordshoaler)
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
Parti = ifelse(Parti == "Det Radikale Venstre","Radikale Venstre", Parti),
month_year_id = paste0(Year,"-", month(Date)) # Making a month and year unique variable
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup() %>%
# Removing all formand because of procedural and lots of mistakes.
filter(!Title %in% c("Formanden","Formand")) %>%
# filtering out all duplicates
group_by(doc_id) %>% filter(n() < 2) %>% ungroup()
############## corpus per month ###################
years = seq(2009,2021) # Years to loop through
df_subset <- df %>% filter(Year %in% years)
months = unique(df_subset$month_year_id) # input list
i=1
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", month, ". Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE, ignoredFeatures = stopwords("danish")) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
map(months, wordshoaler)
df <- df %>%
filter(!Parti %in% parties_to_remove) %>%
# Changing konservative folkeparti
mutate(
Parti = ifelse(Parti == "Konservative Folkeparti","Det Konservative Folkeparti", Parti),
Parti = ifelse(Parti == "Det Radikale Venstre","Radikale Venstre", Parti),
month_year_id = paste0(Year,"-", month(Date)), # Making a month and year unique variable
Month = floor_date(Date, "month")
) %>%
#removing documents with less than 10 speaches
group_by(id) %>%
filter(n() > 10) %>% ungroup() %>%
# Removing all formand because of procedural and lots of mistakes.
filter(!Title %in% c("Formanden","Formand")) %>%
# filtering out all duplicates
group_by(doc_id) %>% filter(n() < 2) %>% ungroup()
View(df_subset)
View(df)
months = unique(df_subset$Month) # input list
############## corpus per month ###################
years = seq(2009,2021) # Years to loop through
df_subset <- df %>% filter(Year %in% years)
months = unique(df_subset$Month) # input list
i=1
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", month, ". Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE, ignoredFeatures = stopwords("danish")) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
map(months, wordshoaler)
months = as.character(unique(df_subset$Month)) # input list
map(months, wordshoaler)
tidyverse::map(months, wordshoaler)
purr::map(months, wordshoaler)
purrr::map(months, wordshoaler)
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", month, ". Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(Month == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE, ignoredFeatures = stopwords("danish")) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
purrr::map(months, wordshoaler)
months = unique(df_subset$month_year_id) # input list
i=1
wordshoaler <- function(month) {
cat(paste0("[ ] Shoaling Month ", month, ". Month: ", i, " out of ", length(months), "\n"))
shoal_df = df_subset %>% filter(month_year_id == paste0(month))
corpuseret = quanteda::corpus(shoal_df)
dfmmm <- dfm(tokens(corpuseret), remove_punct = TRUE, ignoredFeatures = stopwords("danish")) # matrix making
wordshoalfit <- wordshoal::textmodel_wordshoal(dfmmm, groups = docvars(corpuseret, "id"),
authors = docvars(corpuseret, "Name"))
author_positions <- summary(wordshoalfit)$estimated.author.positions
author_positions$row_names <- rownames(author_positions)
fitdf <- merge(author_positions,
docvars(corpuseret),
by.x = "row_names", by.y = "Name")
fitdf <- subset(fitdf, !duplicated(row_names))
thetascores <<- rbind(thetascores, fitdf)
i <<- i + 1
}
thetascores <- data.frame()
purrr::map(months, wordshoaler)
